
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{confidence\_interval - Copy}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Comprehensive Confidence Intervals for Python
Developers}\label{comprehensive-confidence-intervals-for-python-developers}

Variantions of different confidence intervals, their assumptions,
strength and weakness, when to use, and when not to use.

    \begin{quote}
\textbf{Confidence interval} is uncertainty in summary statistic
represented as a range. In the other words, it is a range of values we
are fairly sure our true value lies in. For example: I am 95\% confident
that the population mean falls between 8.76 and 15.88 \(\rightarrow\)
(12.32 \(\pm\) 3.56)
\end{quote}

Confidence interval tells you how confident you can be that the results
from a poll or survey reflect what you would expect to find if it were
possible to survey the entire population. It is difficult to obtain
measurement data of an entire data set (\emph{population}) due to
limited resource \& time. Your best shot is to survey a small fraction
(\emph{samples}) of the entire data set, and pray that your sample data
represents the population reasonably well.

Sample data may not be a good representation of a population by numerous
factors (Ex: bias), and as a result, uncertainty is always introduced in
any estimations derived from sample data. \textbf{Due to the uncertainty
involved with sample data, any statistical estimation needs to be
delivered in a range, not in a point estimate}.

How well a sample statistic estimates an underlying population parameter
is always an issue (Population vs. Samples). A confidence interval
addresses this issue by providing a range of values, which is likely to
contain the population parameter of interest.

    \hypertarget{toc_container}{}
\begin{verbatim}
<p class="toc_title">Contents</p>
<ul class="toc_list">
    <li>
        <a href="#Understanding confidence interval with analogy"><span class="toc_label">1</span>Understanding
            confidence interval with analogy</a>
        <ul>
            <li><a href="#Uncertainty in rock porosity"><span class="toc_label">Example 1:</span>Uncertainty in rock
                porosity</a></li>
            <li><a href="#Purity of methamphetamine (crystal) in Breaking Bad"><span
                    class="toc_label">Example 2:</span>Purity of methamphetamine (crystal) in Breaking Bad</a></li>
        </ul>
    </li>
    <li><a href="#quick-highlights"><span class="toc_label">2</span>Key takeaways</a></li>
    <li><a href="#population_vs_samples"><span class="toc_label">3</span>Population vs Samples</a></li>
    <ul>
        <li><a href="#sample_pop_var"><span class="toc_label">Notes:</span>Population variance $\sigma^2$ vs.
            Sample variance $s^2$</a></li>
        <li><a href="#python_variance"><span class="toc_label">Pythonic Tip:</span>Difference between Numpy variance
            and Pandas variance</a></li>
    </ul>
    <li><a href="#Confidence interval of different statistics"><span class="toc_label">4</span>Confidence interval
        of normal distribution</a></li>
    <ul>
        <li><a href="#conf_int_of_mean"><span class="toc_label">4.1</span>Confidence interval of mean</a></li>
        <ul>
            <li><a href="#dist_stats"><span class="toc_label">Notes:</span>Distribution of various statistics</a>
            </li>
            <li><a href="#t_vs_z"><span class="toc_label">Notes:</span>z-score vs t-score</a></li>
            <li><a href="#python_ci_mean"><span class="toc_label">Pythonic Tip:</span>Computing confidence interval of mean with SciPy</a></li>
        </ul>
        <li><a href="#conf_int_of_diff_in_mean"><span class="toc_label">4.2</span>Confidence interval of difference
            in mean</a></li>
        <ul>
            <li><a href="#anova"><span class="toc_label">Notes:</span>Comparing means of more than two samples with ANOVA</a></li>
            <li><a href="#ind_equal"><span class="toc_label">4.2.1</span>Independent (unpaired) samples, equal
                variance - Student's t-interval</a></li>
            <ul>
                <li><a href="#python_ind_equal"><span class="toc_label">Pythonic Tip:</span>Computing student's t-interval</a></li>
            </ul>
            <li><a href="#ind_unequal"><span class="toc_label">4.2.2</span>Independent (unpaired) samples, unequal variance - Welch's t-interval</a></li>
            <ul>
                <li><a href="#python_ind_unequal"><span class="toc_label">Pythonic Tip:</span>Computing Welch's t-interval</a></li>
            </ul>
            <li><a href="#dep"><span class="toc_label">4.2.3</span>Dependent (paired) samples - Paired t-interval</a></li>
            <ul>
                <li><a href="#python_dep"><span class="toc_label">Pythonic Tip:</span>Computing paired t-interval</a></li>
            </ul>
            <li><a href="#which_to_use"><span class="toc_label">Notes:</span>Deciding which t-test to use</a></li>
        </ul>
        <li><a href="#conf_int_of_var"><span class="toc_label">4.3</span>Confidence interval of variance</a></li>
        <ul>
            <li><a href="#chi_square"><span class="toc_label">Notes:</span>Chi-square $\chi^2$ distribution</a></li>
            <li><a href="#one_tail_two_tail"><span class="toc_label">Notes:</span>One-tail vs two-tail</a></li>
            <li><a href="#python_ci_var"><span class="toc_label">Pythonic Tip:</span>Computing confidence interval of variance with SciPy</a></li>
        </ul>
        <li><a href="#conf_int_of_other"><span class="toc_label">4.4</span>Confidence interval of other statistics: Bootstrap</a></li>
        <li><a href="#"><span class="toc_label">4.5</span>Confidence interval of regression</a></li>
        <li><a href="#"><span class="toc_label">4.6</span>Two-tailed vs one-tailed interval</a></li>
        <li><a href="#robustness"><span class="toc_label">Notes:</span>Robustness of confidence interval to non-normality</a></li>
    </ul>
    <li><a href="#conf_int_non_normal"><span class="toc_label">5</span>Confidence interval of non-normal
        distribution</a></li>
    <ul>
        <li><a href="#"><span class="toc_label">5.1</span>Comparing central tendency of populations</a></li>
            <ul>
                <li><a href="#"><span class="toc_label">5.1.1</span>Confidence interval of median: Mann-Whitney U test</a></li>
            </ul>
        <li><a href="#"><span class="toc_label">5.2</span>Credible interval</a></li>
        <li><a href="#"><span class="toc_label">5.3</span>Transform to normal distribution with Box-Cox</a></li>
        <li><a href="#"><span class="toc_label">5.4</span>Bootstrapping</a></li>
            <ul>
                <li><a href="#"><span class="toc_label">5.4.1</span>Bootstrap CI of statistics</a></li>
                <li><a href="#"><span class="toc_label">5.4.1</span>Bootstrap CI of difference in statistics</a></li>
            </ul>
    </ul>
    <li><a href="#"><span class="toc_label">6</span>FAQ's</a></li>
    <ul>
        <li><a href="#"><span class="toc_label">6.1</span>What is confidence level?</a></li>
        <li><a href="#"><span class="toc_label">6.2</span>What is significance level?</a></li>
        <li><a href="#"><span class="toc_label">6.3</span>What is margin of error?</a></li>
        <li><a href="#"><span class="toc_label">6.4</span>What is degrees of freedom?</a></li>
        <li><a href="#"><span class="toc_label">6.5</span>Non-normality and outliers</a></li>
        <li><a href="#"><span class="toc_label">6.6</span>kurtosis</a></li>
    </ul>
    <li><a href="#"><span class="toc_label">7</span>Worked Python examples</a></li>
</ul>
\end{verbatim}

Prediction interval vs Confidence interval

    \hypertarget{Understandingux20confidenceux20intervalux20withux20analogy}{}

\subsection{1. Understanding confidence interval with
analogy}\label{understanding-confidence-interval-with-analogy}

If you've taken a science class with lab reports in your highschool or
college, you probably had to include measurement error in your lab
reports. For example, if you were asked to measure the length of a paper
clip with a ruler, you have to include \(\pm0.5 \,\text{cm}\) or
\(\pm0.05\,\text{cm}\) (depending on the spacing of tick marks) to
account for the measurement error that shows the precision of your
measuring tool.

Based on figure (1), the paper clip seems to be about 2.7 cm long, but
we don't know for sure because the tickmarks in the ruler is not precise
enough to measure decimal length. However, I can tell with 100\%
confidence that the paper clip has a length between 2 \textasciitilde{}
3 cm, because the clip is between 2cm and 3cm tickmarks. You record the
length of the paper clip in a \emph{range}, instead of a \emph{point
estimate}, to account for the uncertainty introduced by the limitation
of the measuring tool.

\hypertarget{fig1}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_ruler.png"></div>
<div class="col-12"><p class="image-description">Figure 1: Measurement error in ruler</p></div>
\end{verbatim}

Similar idea can be applied to a confidence interval of mean. You want
to obtain a mean of a whole data set (\emph{population}), but you can
measure values of only a small fraction (\emph{samples}) of the whole
data set. This boils down to the traditional issue of Sample vs
Population, due to the cost of obtaining measurement data of a large
data set. Uncertainty is introduced in your samples, because you don't
know if your samples are 100\% representative of the population, free of
bias. Therefore, you deliver your conclusion in a range, not in a point
estimate, to account for the uncertainty.

    \hypertarget{Uncertaintyux20inux20rockux20porosity}{}

Example 1: Uncertainty in rock porosity

A reservoir engineer in the oil \& gas industry wants to know the rock
porosity of a formation to estimate the total oil reserve 9,500 ft
underground. Due to the high cost of obtaining rock core samples from
the deep formations, he could acquire only 12 rock core samples. Since
the uncertainty of a point estimation scales inversely with a sample
size, his estimation is subject to non-negligible uncertainty. He
obtains 14.5\% average rock porosity with 4.3\% standard deviation.
Executives in the company wants to know the worst-case scenario and the
best-case scenario to make business decisions. You can convey your
estimation of average porosity with uncertainty by constructing the
confidence interval of mean.

Assuming that you have a reason to believe that the rock porosity
follows normal distribution, you can construct its 80\% confidence
interval, with the procedure described below:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}133}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.2}\PY{p}{,} \PY{l+m+mi}{12} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{14.5}\PY{p}{,} \PY{n}{scale}\PY{o}{=} \PY{l+m+mf}{4.3} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{12}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}133}]:} (12.807569748569543, 16.19243025143046)
\end{Verbatim}
            
    In the worst-case scenario, the rock formation at 9,500 ft underground
has 12.8\% porosity. In the best-case scenario, the oil reservoir has
16.2\% porosity. The same procedures can be applied for the core samples
collected at different depths, which give us the confidence interval
plot of rock porosities shown in figure (2).

\hypertarget{fig2}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/rock_por_conf_no_title.png"></div>
<div class="col-12"><p class="image-description">Figure 2: Confidence interval of core samples porosities along depths</p></div>
\end{verbatim}

    \begin{verbatim}
<div class="solution_title">
    <p class="solution_title_string">Source Code For Figure (2)</p>
    <ul class="nav navbar-right panel_toolbox">
        <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
    </ul>
<div class="clearfix"></div>
</div>
<div class="solution_content">
    <pre>
        <code class="language-python">
            import numpy as np
            from scipy import stats
            import matplotlib.pyplot as plt

            np.random.seed(39)

            depth = [i * 10 + 8000 for i in range(100)]
            l = len(depth)
            avg_por = []
            p10_por = []
            p90_por = []
            for i, item in enumerate(depth):

                # You collect 12 rock core samples for each depth
                # Assume that sample porosity follows a normal distribution
                sample_size = 12
                por_samples = np.random.normal(loc=0.15 - i/2000, scale=0.022, size=sample_size)
                avg_por.append(np.mean(por_samples))
                
                # 80% confidence interval of mean
                p10, p90 = stats.t.interval(1 - 0.2, sample_size - 1, loc=np.mean(por_samples), scale=stats.sem(por_samples))
                p10_por.append(p10)
                p90_por.append(p90)
            
            # plotting
            plt.style.use('seaborn-whitegrid')
            fig, ax = plt.subplots(1, 2, figsize=(8, 4))

            ax[0].plot(avg_por[:l//2], depth[:l//2], 'k', label='P50', alpha=0.8)
            ax[0].plot(p10_por[:l//2], depth[:l//2], 'grey', linewidth=0.7, label='P10', linestyle='--')
            ax[0].plot(p90_por[:l//2], depth[:l//2], 'grey', linewidth=0.7, label='P90')

            ax[0].set_xlim(0.08, 0.17)
            ax[0].set_ylabel('Depth (ft)', fontsize=15)
            ax[0].set_xlabel('Porosity', fontsize=15)
            ax[0].fill_betweenx(depth[:l//2], p10_por[:l//2], p90_por[:l//2], facecolor='lightgrey', alpha=0.3)
            ax[0].invert_yaxis()

            ax[1].plot(avg_por[l//2:], depth[l//2:], 'k', label='P50', alpha=0.8)
            ax[1].plot(p10_por[l//2:], depth[l//2:], 'grey', linewidth=0.7, label='P10', linestyle='--')
            ax[1].plot(p90_por[l//2:], depth[l//2:], 'grey', linewidth=0.7, label='P90')

            ax[1].set_xlim(0.08, 0.17)
            ax[1].set_xlabel('Porosity', fontsize=15)
            ax[1].legend(loc='best', fontsize=14, framealpha=1, frameon=True)
            ax[1].fill_betweenx(depth[l//2:], p10_por[l//2:], p90_por[l//2:], facecolor='lightgrey', alpha=0.3)
            ax[1].invert_yaxis()
        </code>
    </pre>
</div>
\end{verbatim}

    \hypertarget{Purityux20ofux20methamphetamineux20ux28crystalux29ux20inux20Breakingux20Bad}{}

Example 2: Purity of methamphetamine (crystal) in Breaking Bad

21 batches of crystal cooked by Mr. White shows 99.1\% average purity
with 3\% standard deviation. 18 batches of crystal cooked by Mr. Pinkman
shows 96.2\% average purity with 4\% standard deviation. Does Mr. White
always cook better crystal than Mr. Pinkman, or is it possible for Mr.
Pinkman to beat Mr. White in purity of cooked crystals, by luck?

We can construct 95\% confidence interval assuming normal distribution,
with the procedure described below:

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}78}]:} \PY{c+c1}{\PYZsh{} Mr. White\PYZsq{}s}
         
         \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mi}{21} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{99.1}\PY{p}{,} \PY{n}{scale}\PY{o}{=} \PY{l+m+mi}{3} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{21}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}78}]:} (97.73441637228476, 100.46558362771523)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}79}]:} \PY{c+c1}{\PYZsh{} Mr. Pinkman\PYZsq{}s}
         
         \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mi}{18} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{96.2}\PY{p}{,} \PY{n}{scale}\PY{o}{=} \PY{l+m+mi}{4} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{18}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}79}]:} (94.21084679714819, 98.18915320285181)
\end{Verbatim}
            
    There's a small overlap between the confidence intervals of Mr. White's
and Mr. Pinkman's. Although it is true that Mr. White is a better
cooker, Mr. Pinkman can cook a purer batch of crystals by a small
chance, if he has the luck. Comparing the means of two sample data sets
is closely related to constructing confidence interval of difference in
mean.

\hypertarget{fig2}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/crystal_purity.png"></div>
<div class="col-12"><p class="image-description">Figure 3: Overlap in the 95% confidence interval of two samples</p></div>
\end{verbatim}

    \begin{verbatim}
<div class="solution_title">
    <p class="solution_title_string">Source Code For Figure (3)</p>
    <ul class="nav navbar-right panel_toolbox">
        <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
    </ul>
<div class="clearfix"></div>
</div>
<div class="solution_content">
    <pre>
        <code class="language-python">
            import matplotlib.pyplot as plt
            from scipy import stats
            import numpy as np

            conf_pinkman = stats.t.interval(1 - 0.05, 18 - 1, loc=96.2, scale= 4 / np.sqrt(18))
            conf_white = stats.t.interval(1 - 0.05, 21 - 1, loc=99.1, scale= 3 / np.sqrt(21))

            plt.style.use('seaborn-whitegrid')
            fig, ax = plt.subplots(figsize=(5, 2))

            ax.errorbar(99.1, 1, xerr=(conf_white[1] - conf_white[0]) / 2, 
                        fmt='o', markersize=8, capsize=5, label='Mr. White\'s', color='grey')
            ax.errorbar(96.2, 0, xerr=(conf_pinkman[1] - conf_pinkman[0]) / 2, 
                        fmt='o', markersize=8, capsize=5, label='Mr. Pinkman\'s', color='k')
            ax.set_ylim(-0.6, 1.6)
            ax.fill_betweenx([1, 0], conf_white[0], conf_pinkman[1], facecolor='lightgrey', alpha=0.3)
            ax.legend(loc='best', fontsize=11, framealpha=1, frameon=True)
            ax.set_xlabel('Purity (%)', fontsize=12)
            ax.yaxis.set_major_formatter(plt.NullFormatter())
            fig.tight_layout();
        </code>
    </pre>
</div>
\end{verbatim}

    \hypertarget{quick-highlights}{}

\subsection{2. Key takeaways}\label{key-takeaways}

\hypertarget{key1}{}
\begin{verbatim}
<div class="highlights-title">1. Confidence interval quantifies uncertainty of statistical estimation</div>
<div class="highlights-content">Confidence interval qunatifies the uncertainty related to a statistical estimation to mitigate the issue of <a href="#population_vs_samples">Population vs. Samples</a>. It is always expressed in a range like â€” $\text{C.I.}: \quad \bar{x} \pm 3.43$ or $-51.4 < \bar{x} < -43.2$</div>
\end{verbatim}

\hypertarget{key2}{}
\begin{verbatim}
<div class="highlights-title">2. Confidence interval is the basis of parametric hypothesis tests</div>
<div class="highlights-content">Confidence interval is the basis of parametric hypothesis tests. For example, <a href="https://www.investopedia.com/terms/t/t-test.asp" target="_blank">t-test</a> computes its p-value using the <a href="#conf_int_of_diff_in_mean">confidence interval of difference in mean</a>. When samples follow a normal distribution, and therefore their <a href="#central_tendency">centeral tendency</a> can be described by their means, t-test can be used to conclude if two distributions are significantly different from each other. 
</div>
\end{verbatim}

\hypertarget{key3}{}
\begin{verbatim}
<div class="highlights-title">3. Formula for confidence interval varies with statistics</div>
<div class="highlights-content">
    <p>For <a href="#conf_int_of_mean">confidence interval of mean</a></p>
    <p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{C.I.}_{\text{mean}}: \quad \mu \pm (t_{\frac{\alpha}{2},df} \times \frac{s}{\sqrt{n}})$$</div></p>
    <p>For <a href="#conf_int_of_diff_in_mean">confidence interval of difference in mean</a></p>
    <p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{C.I.}_{\Delta \text{mean}}: \quad (\mu_{1}- \mu_{2}) \pm (t_{1-\frac{\alpha}{2},df} \times \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}})$$</div></p>    
    <p>For confidence interval of proportion</p>
    <p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{C.I.}_{\text{proportion}}: \quad \hat{p} \pm (t_{\frac{\alpha}{2},df} \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}} )$$</div></p>
    <p>For <a href="#conf_int_of_var">confidence interval of variance</a></p>
    <p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{C.I.}_{\text{variance}}: \frac{(n-1)s^{2}}{\chi^{2}_{\frac{\alpha}{2}}} \leq \sigma^2 \leq \frac{(n-1)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2}}}$$</div></p>
    <p>For confidence interval of standard deviation</p>
    <p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{C.I.}_{\text{standard deviation}}: \sqrt{\frac{(n-1)s^{2}}{\chi^{2}_{\frac{\alpha}{2}}}} \leq \sigma \leq \sqrt{\frac{(n-1)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2}}}}$$</div></p>
    <p>Different analytical solutions exist for different statistics. However, confidence interval for many other statistics cannot be analytically solved, simply because there are no formulas for them. If the statistic of your interest does not have an analytical solution for its confidence interval, or you simply don't know it, numerical methods like <a href="https://aegis4048.github.io/non-parametric-confidence-interval-with-bootstrap" target="_blank">boostrapping</a> can be a good alternative (and its powerful).</p>
</div>
\end{verbatim}

\hypertarget{key4}{}
\begin{verbatim}
<div class="highlights-title">4. Things are VERY different if sample data set is not normally distributed</div>
<div class="highlights-content">The equations listed above <b>are not valid if sample data set is not normally distributed</b>. In case of non-normally distributed data, its confidence interval can be obatined with non-parametric methods like <a href="https://aegis4048.github.io/non-parametric-confidence-interval-with-bootstrap" target="_blank">boostrapping</a>, or instead use <a href="#">credible interval</a>, which is a Baysian equivalent of confidence interval. Or you can transform your data into normal distribution using <a href="https://aegis4048.github.io/transforming-non-normal-distribution-to-normal-distribution" target="_blank">Box-Cox transformation</a>.</div>
\end{verbatim}

\hypertarget{key5}{}
\begin{verbatim}
<div class="highlights-title">5. 95% C.I. does not mean 95% of the sample data lie within the interval.</div>
<div class="highlights-content">It means that there's 95% chance that the estimated statistic falls within the interval. 95% confidence interval relates to the reliability of the estimation procedure. Ex: How reliable is your estimation of population variance?</div>
\end{verbatim}

\hypertarget{key6}{}
\begin{verbatim}
<div class="highlights-title">6. Always use t-score instead of z-score</div>
<div class="highlights-content">When constructing confidence interval of mean, or running t-test, always use t-score instead of z-score. This is described in detail <a href="#t_vs_z">below</a>.</div>
\end{verbatim}

\hypertarget{key7}{}
\begin{verbatim}
<div class="highlights-title">7. Bigger sample size gives narrower confidence intervals</div>
<div class="highlights-content">Intuitively, this is because the more samples we have, the less uncertainty we have with our statistical estimation. Mathematically, this is because the the confidence interval is inversely related to the sample size $n$, as shown in <a href="#eq-1">eq (1)</a>.</div>
\end{verbatim}

\hypertarget{key8}{}
\begin{verbatim}
<div class="highlights-title">8. Means are not always equivalent to central tendency</div>
<div class="highlights-content">When samples are not normally distributed, their means are not a good measure of their <a href="#central_tendency">centeral tendencies</a>. For example, if you are comparing the means of two non-normal data sets with t-test to conclude if they came from the same population, your approach is wrong. The more viable alternative would be to use non-parametric alternatives that uses median, or other statistics that capture the central tendency of non-normal distributions.</div>
\end{verbatim}

    \hypertarget{population_vs_samples}{}

\subsection{3. Population vs. samples}\label{population-vs.-samples}

Confidence interval describes the amount of uncertainty associated with
a sample estimate of a population parameter. One needs to have a good
understanding of the difference between samples and population to
understand the necessity of delivering statistical estimations in a
range, a.k.a. confidence interval.

\hypertarget{fig1}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_sample_pops.png"></div>
<div class="col-12"><p class="image-description">Figure 1: Population vs samples</p></div>
\end{verbatim}

\begin{quote}
\textbf{Population}: data set that contains all members of a specified
group. Ex: ALL people living in the US.
\end{quote}

\begin{quote}
\textbf{Samples}: data set that contains a part, or a subset, of a
population Ex: SOME people living in the US.
\end{quote}

Let's say that you are conducting a phone-call survey to investigate the
society's perception of The Affordable Care Act (``Obamacare''). Since
you can't call all 327.2 million people (\emph{population}) in the US,
you call about 1,000 people (\emph{samples}). Your poll showed that 59\%
of the registered voters support Obamacare. This does not agree with the
actual survey conducted in 2018; 53\% favorable, 42\% unfavorable
(source). What could be the source of error?

Since (formal) president Obama is a member of the Democratic Party, the
voters' response can be affected by their political preference. How
could you tell that the 1,000 people you called happened to be mostly
Democrats, who's more likely to support Obama's policy, because they
share similar political view? The samples you collected could have been
\emph{biased}, but you don't that know for sure. Of course, the voters'
response could be affected by many other factors like race, age, place
of residence, or financial status. The idea is that, there will always
be uncertainty involved with your estimation, because you don't have an
access to the entire population.

Confidence interval is a technique that quantifies the uncertainty when
estimating a population parameter from samples.

\hypertarget{sample_pop_var}{}

\begin{verbatim}
<h4>Notes: Population variance $\sigma^2$ vs. Sample variance $s^2$</h4>
<p>Distinction between population parameter and sample parameter is important. In statistics, it is a common practice to denote population variance as $\sigma^2$, and sample variance as $s^2$. The distinction is important because different equations are used for each.</p>
<p>For population:</p>
<p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{variance} = \sigma^2 = \frac{\sum(x - \bar{x})^2}{n} $$</div></p>
<p>For samples:</p>
<p><div style="font-size: 1rem; margin-top: 20px;">$$ \text{variance} = s^2 = \frac{\sum(x - \bar{x})^2}{n-1} $$</div></p>
<p>The divisor $n-1$ is a correction factor for bias. Note that the correction has a larger proportional effect when $n$ is small than when $n$ is large, which is what we want because the more samples we have, the better the estimation. This idea is well explained on this <a href="https://stats.stackexchange.com/questions/3931/intuitive-explanation-for-dividing-by-n-1-when-calculating-standard-deviation" target="_blank">StackExchange thread</a>.</p>
\end{verbatim}

\hypertarget{python_variance}{}

Pythonic Tip: Difference between Numpy variance and Pandas variance

Different libraries make different assumption about an input array. The
default value of ddof is different for Pandas and Numpy, resulting in
different variance. ddof represent degrees of freedom, and setting
ddof=True or ddof=1 tells the variance function to calculate sample
variance by accounting for the bias factor \(n-1\) (recall that in
Python, True==1.) Remember that there is a distinction between
Population variance (\(\sigma^2\)) vs. Sample variance (\(s^2\)).

If you are confused which library is computing which variance (sample or
population), just remember this: whatever library you are using, use
ddof=True or ddof=1 to compute sample variance, and use ddof=False or
ddof=0 to compute population variance.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        
        \PY{n}{arr} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{c+c1}{\PYZsh{} numpy, population}
        \PY{n}{arr}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} 3.6875
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} numpy, sample}
        \PY{n}{arr}\PY{o}{.}\PY{n}{values}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} 4.916666666666667
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{c+c1}{\PYZsh{} pandas, population}
         \PY{n}{arr}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}10}]:} 0    3.6875
         dtype: float64
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}99}]:} \PY{c+c1}{\PYZsh{} pandas, sample}
         \PY{n}{arr}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}99}]:} 0    4.916667
         dtype: float64
\end{Verbatim}
            
    \hypertarget{Confidenceux20intervalux20ofux20differentux20statistics}{}

\subsection{4. Confidence interval of normal
distribution}\label{confidence-interval-of-normal-distribution}

Computing confidence interval of a statistic depends on two factors:
type of statistic, and type of sample distribution. As explained above,
different formulas exist for different type of statistics (Ex: mean,
std, variance), and different methods (Ex: boostrapping, credible
interval, Box-Cox transformation) are used for non-normal data set.

We will cover confidence interval of mean, difference in mean and
variance.

    \hypertarget{conf_int_of_mean}{}

\subsubsection{4.1. Confidence interval of
mean}\label{confidence-interval-of-mean}

Confidence interval of mean is used to estimate the population mean from
sample data and quantify the related uncertainty. Consider the following
figure:

\hypertarget{fig3}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_pop_dist.png"></div>
<div class="col-12"><p class="image-description">Figure 3: Distribution of population and C.I. of mean</p></div>
\end{verbatim}

In figure (3), assume that the population is normally distributed. Since
we don't have an excess to the entire population, we have to guess the
{population mean (unknown)} to the best of our ability using sample data
set. We do this by computing the {sample mean} and constructing its
{95\% confidence interval}. Note that the popular choices of confidence
levels are: 90\%, 95\%, and 99\%

Assuming normality of population, its sample means are also normally
distributed. Let's say that you have a population, and you draw small
fractions of it \(N\) times. Then, the computed means of \(N\) sample
sets \(\boldsymbol{\mu}=(\mu_1, \mu_2,..., \mu_{N-1}, \mu_N)\) is
normally distributed as shown in figure (4). Their confidence intervals
are represented as the black horizontal arrows:.

\hypertarget{fig4}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_mean.png"></div>
<div class="col-12"><p class="image-description">Figure 4: Distribution of sample mean and its C.I.</p></div>
\end{verbatim}

You can see that the confidence interval of {\(\mu_5\)} does NOT include
the {green vertical dashed line}, 12.31. Let's assume that 12.31 is the
true population mean (we never know if this is the actual population
mean or not, but let's assume). If we get {\(\mu_5\)} and its confidence
interval as our estimation of the population mean, then our estimation
is wrong. There is a 5\% chance of this happening, because we set our
confidence level as 95\%. Note that the width of the confidence
intervals (black horizontal arrows) depend on the sample size, as shown
in eq (1)

The grey area of figure (3) is essentially equivalent to the grey area
of figure (4). \(\mu_1\) = 12.32 is the sample mean, and \(\pm\) 3.56 is
the uncertainty related to the sample mean with 95\% confidence. The
uncertainty is a product of distribution score and standard error of
mean. Distribution score essentially tells how many standard error are
the limits (8.76 and 15.88) away from the center (12.32). Choosing
larger confidence level results in larger confidence interval. This
increases the grey area in figure (3) and figure (4).

We convey 95\% confidence interval of mean like this:

\begin{quote}
I am 95\% confident that the population mean falls between 8.76 and
15.88. If I sample data 20 times, 19 times the sample mean will fall
between 8.76 \textasciitilde{} 15.88, but expect that I will be wrong 1
time.
\end{quote}

\hypertarget{dist_stats}{}

\begin{verbatim}
<h4>Notes: Distribution of various statistics</h4>
<p>Different statistics exhibit different distributions. Normality of samples does not guarantee normality of its statistics. When the samples are normally distributed, their means are normally distributed, but their variances are chi-square <span style="font-size: 90% !important">$\chi^2$</span> distributed. More discussion about the distribution of variance and <span style="font-size: 90% !important">$\chi^2$</span> distribution is covered <a href="#chi_square">below</a>. Note that these assumptions are invalid when samples are non-normal.</p>
<img class="" style="border: 1px solid #ddd;" src="jupyter_images/chi_norm.png"/>
<div class="solution_panel closed" style="margin-top: 20px;">
    <div class="solution_title solution_admonition">
        <p class="solution_title_string">Source Code For The Figure</p>
        <ul class="nav navbar-right panel_toolbox">
            <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
        </ul>
        <div class="clearfix"></div>
    </div>
    <div class="solution_content">
        <pre>
            <code class="language-python">
                from scipy import stats
                import matplotlib.pyplot as plt
                import numpy as np

                df_values = [1, 2, 6, 9]
                linestyles = ['-', '--', ':', '-.']
                normal_params = [(10, 1), (11, 1), (10, 2), (10, 3)]
                x = np.linspace(-1, 20, 1000)

                fig, ax = plt.subplots(1, 2, figsize=(13.3, 5))
                fig.tight_layout()
                plt.subplots_adjust(left=0.09, right=0.96, bottom=0.12, top=0.93)

                for df, norm_p, ls in zip(df_values, normal_params, linestyles):
                    ax[1].plot(x, stats.chi2.pdf(x, df, loc=0, scale=1),
                               ls=ls, c='black', label=r'Degrees of freedom$=%i$' % df)
                    ax[0].plot(x, stats.norm.pdf(x, loc=norm_p[0], scale=norm_p[1]), 
                               ls=ls, c='black', label='Mean = %d, ' % norm_p[0] + 'Std = %s' % norm_p[1])

                ax[0].set_xlim(4, 16)
                ax[0].set_ylim(-0.025, 0.525)
                ax[0].set_xlabel('$x$', fontsize=20)
                ax[0].set_ylabel(r'Probability', fontsize=20)
                ax[0].set_title(r'Distribution of means: normal distribution', fontsize=20)
                ax[0].legend(loc='upper left', fontsize=16, framealpha=1, frameon=True)

                ax[1].set_xlim(0, 10)
                ax[1].set_ylim(-0.025, 0.525)
                ax[1].set_xlabel('$\chi^2$', fontsize=20)
                ax[1].set_title(r'Distribution of variances: $\chi^2$ distribution', fontsize=20)
                ax[1].legend(loc='best', fontsize=16, framealpha=1, frameon=True)
            </code>
        </pre>
    </div>
</div>
\end{verbatim}

    If sample data is normal or normal-like distributed, we almost always
assume t-distribution to compute confidence interval, as explained
below. Then, the confidence interval of mean has the following
analytical solution:

\hypertarget{eq-1}{}
\[ \text{C.I.}_{\text{mean}}: \quad \mu \pm (t_{1-\frac{\alpha}{2},df} \times \frac{s}{\sqrt{n}}) \tag{1}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\mu$<p></div>
    <div class="col-9"><p>: sample mean<p></div>
</div>
<div class="row">
    <div class="col-3">$\alpha$</div>
    <div class="col-9">: <a href="#">significance level</a></div>
</div>    
<div class="row">
    <div class="col-3"><p>$n$<p></div>
    <div class="col-9"><p>: number of samples<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$df$<p></div>
    <div class="col-9"><p>: degrees of freedom. In this example, df = $n$ - 1<p></div>
</div>    
<div class="row">
    <div class="col-3">$s$</div>
    <div class="col-9">: sample standard deviation</div>
</div>   
<div class="row">
    <div class="col-3">$t$</div>
    <div class="col-9">: t-score. depends on $\alpha$ and $df$</div>
</div>   
\end{verbatim}

Recall that when computing \(s\), correction factor (\(n-1\)) is applied
to account for sample bias, as explained above. Pay close attention to
the standard error \(\frac{s}{\sqrt{(n)}}\). As the sample size \(n\)
increases, the standard error decreases, reducing the range of
confidence interval. This is intuitive in a sense that, the more samples
we have, the less uncertainty we have with our statistical estimation.
The length of the black horizontal arrows in figure (4) depends on the
sample size. The larger the sample size, the narrower the width of
arrows, and vice versa.

\hypertarget{t_vs_z}{}

\begin{verbatim}
<h4>Notes: z-score vs t-score</h4>
<p>You've probably seen mixed use of z-score and t-score for confidence interval during your studies. Long story short, it is safe and almost always better to use t-score than z-score.</p>
<p>Z-score ($z_{\frac{\alpha}{2}}$) is used for normal distribution, and t-score ($t_{\frac{\alpha}{2},df}$) is used for t-distribution. You use z-score if you know the population variance $\sigma^2$. If not, you use t-score. Since the population variance $\sigma^2$ is almost never known, you almost always use t-score for confidence interval. After all, the purpose of using confidence interval is to mitigate the issue of <a href="#population_vs_samples">Population vs. Samples</a> when estimating population parameter ($\sigma^2$) from samples. If you know the population parameters, you probably don't need confidence interval in the first place.</p>
<p>A natural question is, "how is it safe to use t-score instead of z-score? Shouldn't I be using z-score since I know that the population is normally distributed, from previous knowledge?" It is safe to do so because t-distribution converges to normal distribution according to the Centeral Limit Theorem. Recall that t-distribution behaves more and more like a normal distribution as the sample size increases.</p>
<p>Google <i>"95% confidence z-score"</i> and you will see $z$ = 1.96 at 95% confidence level. On the other hand, t-score approaches  1.96 as its degrees of freedom increases: $\lim_{df \to \infty}t$ = 1.96. For 95% confidence level, $t$ = 2.228 when $n$ - 1 = 10 and $t$ = 2.086 when $n$ - 1 = 20. This is why it is safe to always replace z-score with t-score when computing confidence interval.</p>
\end{verbatim}

    \hypertarget{python_ci_mean}{}

Pythonic Tip: Computing confidence interval of mean with SciPy

We can compute confidence interval of mean directly from using eq (1).
Recall to pass ddof=1 to make sure to compute sample standard deviation
\(s\), not population standard deviation \(\sigma\), as explained above.

We will draw random samples from normal distribution using
np.random.normal(). Note that loc is for population mean, and scale is
for population standard deviation, and size is for number of samples to
draw.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}128}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
          
          \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
          
          \PY{n}{arr} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{normal}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{74}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mf}{4.3}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{20}\PY{p}{)}
          
          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}                       \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
          \PY{n}{df} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}                  \PY{c+c1}{\PYZsh{} degress of freedom = 20}
          \PY{n}{t} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}   \PY{c+c1}{\PYZsh{} two\PYZhy{}tailed 95\PYZpc{} confidence t\PYZhy{}score = 2.086}
          \PY{n}{s} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{arr}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}            \PY{c+c1}{\PYZsh{} sample standard deviation = 2.502}
          \PY{n}{n} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)}
          
          \PY{n}{lower} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{p}{(}\PY{n}{t} \PY{o}{*} \PY{n}{s} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{n}\PY{p}{)}\PY{p}{)}
          \PY{n}{upper} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{+} \PY{p}{(}\PY{n}{t} \PY{o}{*} \PY{n}{s} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{n}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}129}]:} \PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}129}]:} (71.33139551903422, 75.19543685256606)
\end{Verbatim}
            
    Or we can compute with scipy.stats.t.interval(). Note that you don't
divide alpha by 2, because the function does that for you. Also note
that the standard error \(\frac{s}{\sqrt{n}}\) can be computed with
scipy.stats.sem()

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}130}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{arr}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{arr}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}130}]:} (71.33139551903422, 75.19543685256606)
\end{Verbatim}
            
    Note the default value of loc=0 and scale=1. This will assume sample
mean \(\mu\) to be 0, and standard error \(\frac{s}{\sqrt{n}}\) to be 1,
which assumes standard normal distribution of mean = 0 and standard
deviation = 1. This is NOT what we want.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} (-2.093024054408263, 2.093024054408263)
\end{Verbatim}
            
    \hypertarget{conf_int_of_diff_in_mean}{}

\subsubsection{4.2. Confidence interval of difference in
mean}\label{confidence-interval-of-difference-in-mean}

Confidence interval of difference in mean is not very useful by itself.
But it is important to understand how it works, because it forms the
basis of one of the most widely used hypothesis test: t-test.

Often we are interested in knowing if two distributions are
significantly different. In the other words, we want to know if two
sample data sets came from the same population by comparing central
tendency of populations. A standard approach is to check if the sample
means are different. However, this is a misleading approach in a sense
that the means of samples are almost always different, even if the
difference is microscopic. More useful would be to estimate the
difference in a range to account for uncertainty, and compute
probability that it is big enough to be of practical importance. T-test
checks if the difference is "close enough" to zero by computing the
confidence interval of difference in means.

T-test hypothesis

\[ H_0: \mu_1 - \mu_2 = 0 \tag{2}\]

\[ H_1: \mu_1 - \mu_2 \neq 0 \tag{3}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\mu$<p></div>
    <div class="col-9"><p>: sample mean<p></div>
</div> 
<div class="row">
    <div class="col-3"><p>$H_0$<p></div>
    <div class="col-9"><p>: null hypothesis â€” sample means are the same "enough"<p></div>
</div>
<div class="row">
    <div class="col-3">$H_1$</div>
    <div class="col-9"><p>: alternate hypothesis â€” sample means are "significantly" different</p></div>
</div>    
\end{verbatim}

Note that the above hypothesis tests whether the mean of one group is
significantly DIFFERENT from the mean of the other group; we are using
two-tailed test. This does not check if the mean of one group is
significantly GREATER than the mean of the other group, which uses
one-tailed test.

\hypertarget{anova}{}

\begin{verbatim}
<h4>Notes: Comparing means of more than two samples with ANOVA</h4>
<p>Analysis of variance (ANOVA) checks if the means of two or more samples are significantly different from each other. Using t-test is not reliable in cases where there are more than 2 samples. If we conduct multiple t-tests for comparing more than two samples, it will have a compounded effect on the error rate of the result.</p>
<p>ANOVA has the following hypothesis:</p>
<p><div style="font-size: 1rem; margin-top: 20px;">$$
    \begin{align}
       H_0: &\mu_1 = \mu_2 = \, \cdots \, =\mu_L \\[5pt]
       H_1: &\mu_a \neq \mu_b
    \end{align}
$$</div></p>
<p>where $L$ is the number of groups, and $\mu_a$ and $\mu_b$ belong to any two sample means of any groups. <a href="https://www.analyticsvidhya.com/blog/2018/01/anova-analysis-of-variance/" target="_blank">This article</a> illustrates the concept of ANOVA very well.</p>
\end{verbatim}

    \hypertarget{fig5}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_diff_means.png"></div>
<div class="col-12"><p class="image-description">Figure 5: Distributions of samples</p></div>
\end{verbatim}

In figure (5), \(\mu\) represents the sample mean. If two sample data
sets are from the same population, the distribution of means will be
similar "enough". If not, they will be "significantly" different. It can
be visually inspected by the area of overlap. The larger the overlap,
the bigger the chance of the two distributions originating from the same
population.

The more robust way to compare sample means would be to construct the
confidence interval of difference in means. If the two samples came from
the same population, they should have the similar "enough" means. Their
difference should be close to zero and satisfy (or fail to reject) the
null hypothesis {\(H_0: \mu_1 - \mu_2 = 0\)} within a range of
uncertainty. Consider the following figure:

\hypertarget{fig6}{}
\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_diff_means_dist.png"></div>
<div class="col-12"><p class="image-description">Figure 6: Distribution of difference in means</p></div>
\end{verbatim}

In figure (6), the calculated difference in sample means is
{\(\mu_1 - \mu_2 = 1.00\)}. We deliver the uncertainty related to our
estimation of difference in sample means by constructing its {95\%
confidence interval \([\)-1.31 \textasciitilde{} 3.31\(]\)}. Since the
null hypothesis {\(H_0: \mu_1 - \mu_2 = 0\)} is within the 95\%
confidence interval ({grey shaded area}), we accept the null hypothesis;
we conclude that the samples have the same means within the uncertainty.

However, if the null hypothesis is not within the confidence interval
and falls in the \textbf{2.5\% outliers} zone, we reject the null
hypothesis and accept the alternate hypothesis
{\(H_1: \mu_1 - \mu_2 \neq 0\)}. In the other words, we conclude that
the sample means are significantly different.

    Three variations of confidence interval of difference in means

There are three variations of t-test, and therefore there are three
variations of confidence interval of difference in means. The difference
\& application of the three variations are really well-explained in
Wikipedia (one of the few that are actually easy to understand, with
minimum jargons.)

\begin{verbatim}
<li><a href="#ind_equal">Independent (unpaired) samples, equal variance - Student's t-interval</a></li>
<li><a href="#ind_unequal">Independent (unpaired) samples, unequal variance - Welch's t-interval</a></li>
<li><a href="#dep">Dependent (paired) samples</a></li>
\end{verbatim}

Recall that all t-tests assume normality of data. However, they are
pretty robust to non-normality as long as the deviation from normality
isn't large. Visualize your distributions to test this. Robustness of
t-test to non-normality is discussed in detail below.

    \hypertarget{ind_equal}{}

\paragraph{4.2.1. Independent (unpaired) samples, equal variance -
student's
t-interval}\label{independent-unpaired-samples-equal-variance---students-t-interval}

When you have a reason to believe that samples have nearly equal
variances, you can use student's t-test to check if difference in means
are significantly different. Note that student's t-test works pretty
well even with unequal variances as long as sample sample sizes are
equal or nearly equal, and sample sizes are not tiny.

However, it is recommended to always use Welch's t-test by assuming
unequal variances, as explained below. Use student's t-test if you are
ABSOLUTELY sure that the population variances are nearly equal.

Confidence interval of difference in mean assuming equal variance
(student's t-interval) can be calculated as follows:

\hypertarget{eq-4}{}
\[ \text{C.I.}_{\Delta \text{mean}}: \quad (\mu_{1}- \mu_{2}) \pm (t_{1-\frac{\alpha}{2},df} \times s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}})\,, \quad s_p = \sqrt{\frac{(n_1-1)s_{1}^2 + (n_2-1)s_{2}^2}{n_1+n_2-2}} \tag{4}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\mu$<p></div>
    <div class="col-9"><p>: sample mean<p></div>
</div>
<div class="row">
    <div class="col-3">$\alpha$</div>
    <div class="col-9">: <a href="#">significance level</a></div>
</div>    
<div class="row">
    <div class="col-3"><p>$n$<p></div>
    <div class="col-9"><p>: number of samples<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$df$<p></div>
    <div class="col-9"><p>: degrees of freedom<p></div>
</div>    
<div class="row">
    <div class="col-3">$s_p$</div>
    <div class="col-9">: pooled standard deviation</div>
</div>  
<div class="row">
    <div class="col-3">$s$</div>
    <div class="col-9">: sample standard deviation</div>
</div>   
<div class="row">
    <div class="col-3">$t$</div>
    <div class="col-9">: t-score. depends on $\alpha$ and degrees of freedom $n-1$</div>
</div>   
\end{verbatim}

The formula for the pooled standard deviation \(s_p\) looks a bit
overwhelming, but its just an weighted average standard deviation of two
samples, with bias correction factor \(n_i-1\) for each sample. Recall
that student's t-test assumes equal variances of two samples. You
calculate what is assumed to be the common variance (=pooled variance,
\(s_p^2\)) by computing the weighted average from each sample's
variance.

In eq (4), \(t\)-score depends on significance level \(\alpha\) and
degrees of freedom \(df\). In student's t-test, which assumes equal
variance:

\hypertarget{eq-5}{}
\[ df = n_1 + n_2 -2 \tag{5}\]

    \hypertarget{python_ind_equal}{}

Pythonic Tip: Computing student's t-interval

Unfortunately, SciPy doesn't support computing confidence intereval of
difference in mean separately. It is incorporated into computing
t-statistic and p-value of t-test, but users can't access its underlying
confidence interval. Note that in R, users have access to the CI of
difference in means.

We can compute CI of difference in means assuming equal variance with eq
(4). Don't forget to compute sample variance, instead of population
variance by setting ddof=1 as explained above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}182}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}183}]:} \PY{n}{x1} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{12.9}\PY{p}{,} \PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{7.4}\PY{p}{,} \PY{l+m+mf}{7.0}\PY{p}{,} \PY{l+m+mf}{10.5}\PY{p}{,} \PY{l+m+mf}{11.9}\PY{p}{,} \PY{l+m+mf}{7.1}\PY{p}{,} \PY{l+m+mf}{9.9}\PY{p}{,} \PY{l+m+mf}{14.4}\PY{p}{,} \PY{l+m+mf}{11.3}\PY{p}{]}
          \PY{n}{x2} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{6.9}\PY{p}{,} \PY{l+m+mf}{10.9}\PY{p}{,} \PY{l+m+mf}{11.0}\PY{p}{,} \PY{l+m+mf}{10.1}\PY{p}{,} \PY{l+m+mf}{5.3}\PY{p}{,} \PY{l+m+mf}{7.5}\PY{p}{,} \PY{l+m+mf}{10.3}\PY{p}{,} \PY{l+m+mf}{9.2}\PY{p}{,} \PY{l+m+mf}{8.8}\PY{p}{]}
          
          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}                                                 \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
          \PY{n}{n1}\PY{p}{,} \PY{n}{n2} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}                                    \PY{c+c1}{\PYZsh{} sample sizes}
          \PY{n}{s1}\PY{p}{,} \PY{n}{s2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}              \PY{c+c1}{\PYZsh{} sample variances}
          \PY{n}{s} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{p}{(}\PY{p}{(}\PY{n}{n1} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{*} \PY{n}{s1} \PY{o}{+} \PY{p}{(}\PY{n}{n2} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{*} \PY{n}{s2}\PY{p}{)} \PY{o}{/} \PY{p}{(}\PY{n}{n1} \PY{o}{+} \PY{n}{n2} \PY{o}{\PYZhy{}} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} pooled standard deviation}
          \PY{n}{df} \PY{o}{=} \PY{n}{n1} \PY{o}{+} \PY{n}{n2} \PY{o}{\PYZhy{}} \PY{l+m+mi}{2}                                             \PY{c+c1}{\PYZsh{} degrees of freedom}
          \PY{n}{t} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}                             \PY{c+c1}{\PYZsh{} two\PYZhy{}tailed 95\PYZpc{} confidence t\PYZhy{}score}
          
          \PY{n}{lower} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{t} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{n}{s}
          \PY{n}{upper} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{n}{t} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{n}{s}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}184}]:} \PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}184}]:} (-0.8520326742900641, 3.332032674290068)
\end{Verbatim}
            
    The 95\% confidence interval of difference in means has 0 within its
interval. This means that the null hypothesis,
{\(H_0: \mu_1 - \mu_2 = 0\)} in figure (6), falls within the interval
and we fail to reject the null hypothesis. We conclude that the sample
means are not significantly different.

We can confirm this by running a formal hypothesis testing with
scipy.stats.ttest\_ind(), and setting equal\_var=True. Note that this
assumes independent t-test with pooled variance, which is equivalent to
student's t-test.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}185}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{equal\PYZus{}var}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}185}]:} Ttest\_indResult(statistic=1.2452689491491107, pvalue=0.22900078577218805)
\end{Verbatim}
            
    The computed pvalue=0.229 is bigger than the significance level of alpha
= 0.05, and therefore we fail to reject the null hypothesis, which is
consistent with the conclusion drawn from the confidence interval of
difference in mean.

Checking results with R:

    \hypertarget{ind_unequal}{}

\paragraph{4.2.2. Independent (unpaired) samples, unequal variance -
Welch's
t-interval}\label{independent-unpaired-samples-unequal-variance---welchs-t-interval}

When comparing central tendency of normal distributions, it is safer,
and therefore recommended to always use Welch's t-test, which assumes
unequal variances of samples, as explained below. Equal variance t-test
is not robust when population variances are different, but unequal
variances are robust even when population variances are equal.

Confidence interval of difference in mean assuming unequal variance
(Welch's t-interval) can be calculated as follows:

\hypertarget{eq-6}{}
\[ \text{C.I.}_{\Delta \text{mean}}: \quad (\mu_{1}- \mu_{2}) \pm (t_{1-\frac{\alpha}{2},df} \times \sqrt{\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}}) \tag{6}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\mu$<p></div>
    <div class="col-9"><p>: sample mean<p></div>
</div>
<div class="row">
    <div class="col-3">$\alpha$</div>
    <div class="col-9">: <a href="#">significance level</a></div>
</div>    
<div class="row">
    <div class="col-3"><p>$n$<p></div>
    <div class="col-9"><p>: number of samples<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$df$<p></div>
    <div class="col-9"><p>: degrees of freedom<p></div>
</div>    
<div class="row">
    <div class="col-3">$s$</div>
    <div class="col-9">: sample standard deviation</div>
</div>   
<div class="row">
    <div class="col-3">$t$</div>
    <div class="col-9">: t-score. depends on $\alpha$ and degrees of freedom $n-1$</div>
</div>   
\end{verbatim}

The formula is very similar to student's t-interval. There are two main
differences:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We use each sample's own variance \(s_1^2\) and \(s_2^2\), instead of
  pooled (weighted average) variance \(s_p^2\).

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \setcounter{enumii}{1}
  \tightlist
  \item
    Degrees of freedom {\(df\)} is computed with eq (7).
  \end{enumerate}
\end{enumerate}

\hypertarget{eq-7}{}
\[ df = \frac{(\frac{s^2_1}{n_1} + \frac{s^2_2}{n_2})^2}{\frac{(s^2_1/n_1)^2}{n_1-1} + \frac{(s^2_2/n_2)^2}{n_2-1}} \tag{7}\]

    \hypertarget{python_ind_unequal}{}

Pythonic Tip: Computing Welch's t-interval

The procedure is very similar to Computing student's t-interval. We will
compute confidence interval of difference in mean assuming unequal
variance, with eq (6). Although Scipy supports computing t-statistic for
Welch's t-test, it doesn't support a function that allows us to compute
Welch's t-interval. We will have to write our own codes to compute it.

Don't forget to compute sample variance, instead of population variance
by setting ddof=1 as explained above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}186}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}187}]:} \PY{n}{x1} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{12.9}\PY{p}{,} \PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{7.4}\PY{p}{,} \PY{l+m+mf}{7.0}\PY{p}{,} \PY{l+m+mf}{10.5}\PY{p}{,} \PY{l+m+mf}{11.9}\PY{p}{,} \PY{l+m+mf}{7.1}\PY{p}{,} \PY{l+m+mf}{9.9}\PY{p}{,} \PY{l+m+mf}{14.4}\PY{p}{,} \PY{l+m+mf}{11.3}\PY{p}{]}
          \PY{n}{x2} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{6.9}\PY{p}{,} \PY{l+m+mf}{10.9}\PY{p}{,} \PY{l+m+mf}{11.0}\PY{p}{,} \PY{l+m+mf}{10.1}\PY{p}{,} \PY{l+m+mf}{5.3}\PY{p}{,} \PY{l+m+mf}{7.5}\PY{p}{,} \PY{l+m+mf}{10.3}\PY{p}{,} \PY{l+m+mf}{9.2}\PY{p}{,} \PY{l+m+mf}{8.8}\PY{p}{]}
          
          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}                                                       \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
          \PY{n}{n1}\PY{p}{,} \PY{n}{n2} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}                                          \PY{c+c1}{\PYZsh{} sample sizes}
          \PY{n}{s1}\PY{p}{,} \PY{n}{s2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}                    \PY{c+c1}{\PYZsh{} sample variances}
          \PY{n}{df} \PY{o}{=} \PY{p}{(}\PY{n}{s1}\PY{o}{/}\PY{n}{n1} \PY{o}{+} \PY{n}{s2}\PY{o}{/}\PY{n}{n2}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{/} \PY{p}{(}\PY{p}{(}\PY{n}{s1}\PY{o}{/}\PY{n}{n1}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{o}{/}\PY{p}{(}\PY{n}{n1}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{+} \PY{p}{(}\PY{n}{s2}\PY{o}{/}\PY{n}{n2}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{o}{/}\PY{p}{(}\PY{n}{n2}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} degrees of freedom}
          \PY{n}{t} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}                                   \PY{c+c1}{\PYZsh{} two\PYZhy{}tailed 95\PYZpc{} confidence t\PYZhy{}score}
          
          \PY{n}{lower} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{t} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{n}{s}
          \PY{n}{upper} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{+} \PY{n}{t} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{n}{s}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}188}]:} \PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}188}]:} (-0.8633815129922358, 3.3433815129922397)
\end{Verbatim}
            
    The 95\% confidence interval of difference in means has 0 within its
interval. This means that the null hypothesis,
{\(H_0: \mu_1 - \mu_2 = 0\)} in figure (6), falls within the interval
and we fail to reject the null hypothesis. We conclude that the sample
means are not significantly different.

We can confirm this by running a formal hypothesis testing with
scipy.stats.ttest\_ind(), and setting equal\_var=False. Note that this
assumes independent t-test with pooled variance, which is equivalent to
student's t-test.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}189}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{equal\PYZus{}var}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}189}]:} Ttest\_indResult(statistic=1.245268949149111, pvalue=0.23018336828903668)
\end{Verbatim}
            
    The computed pvalue=0.230 is bigger than the significance level of alpha
= 0.05, and therefore we fail to reject the null hypothesis, which is
consistent with the conclusion drawn from the confidence interval of
difference in mean.

Checking results with R:

    \hypertarget{dep}{}

\paragraph{4.2.3. Dependent (paired) samples - Paired
t-interval}\label{dependent-paired-samples---paired-t-interval}

This test is used when the samples are dependent; that is, when there is
only one sample that has been tested twice (repeated measures) or when
there are two samples that have been matched or "paired" (paired or
unpaired? read below.)

Confidence interval of difference in means assuming paired samples can
be calculated as follows:

\hypertarget{eq-8}{}
\[ \text{C.I.}_{\Delta \text{mean}}: \quad \bar{d} \pm (t_{1-\frac{\alpha}{2}, df} \times \frac{s_d}{\sqrt{n}})\tag{8}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\bar{d}$<p></div>
    <div class="col-9"><p>: average of sample differences<p></div>
</div>
<div class="row">
    <div class="col-3">$\alpha$</div>
    <div class="col-9">: <a href="#">significance level</a></div>
</div>    
<div class="row">
    <div class="col-3"><p>$n$<p></div>
    <div class="col-9"><p>: number of samples<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$df$<p></div>
    <div class="col-9"><p>: degrees of freedom<p></div>
</div>    
<div class="row">
    <div class="col-3">$s_d$</div>
    <div class="col-9">: standard deviation of sample differences</div>
</div>   
<div class="row">
    <div class="col-3">$t$</div>
    <div class="col-9">: t-score. depends on $\alpha$ and degrees of freedom $n-1$</div>
</div>   
\end{verbatim}

The equation is very similar to eq (1), except that we are computing
mean and standard deviation of differences between before \& after state
of test subjects. Let's try to understand this with an example.

A school develops a tutoring program to improve the SAT scores of high
school students. A school requires students to take tests before \&
after tutoring, and checks if the tutoring had a significant impact on
the SAT scores of students. Because the test subjects are compared to
themselves, not anyone elses, the measurements taken before \& after the
training are not independent.

To compute dependent t-interval, we compute differences of test scores
before \& after tutoring:

\begin{verbatim}
<thead>
    <tr>
        <th>Student #</th>
        <th>$X_1$</th>
        <th>$X_2$</th>
        <th>$X_1$ - $X_2$</th>
    </tr>
</thead>
<tbody>
    <tr>
        <td>1</td>
        <td>1480</td>
        <td>1510</td>
        <td>-30</td>
    </tr>
    <tr>
        <td>2</td>
        <td>1280</td>
        <td>1460</td>
        <td>-180</td>
    </tr>
    <tr>
        <td>3</td>
        <td>890</td>
        <td>1320</td>
        <td>-430</td>
    </tr>
    <tr>
        <td>4</td>
        <td>340</td>
        <td>700</td>
        <td>-360</td>
    </tr>
    <tr>
        <td>5</td>
        <td>1550</td>
        <td>1550</td>
        <td>0</td>
    </tr>
    <tr>
        <td>6</td>
        <td>1230</td>
        <td>1420</td>
        <td>-190</td>
    </tr>
    <tr>
        <td>7</td>
        <td>1010</td>
        <td>1340</td>
        <td>-330</td>
    </tr>
    <tr>
        <td>8</td>
        <td>1590</td>
        <td>1570</td>
        <td>20</td>
    </tr>
    <tr>
        <td>9</td>
        <td>1390</td>
        <td>1500</td>
        <td>-110</td>
    </tr>
    <tr>
        <td>10</td>
        <td>980</td>
        <td>1300</td>
        <td>-320</td>
    </tr>       
</tbody>
\end{verbatim}

We find \(\bar{d}\) = -193.0, and \(s_d\) = 161.7. These values are
plugged into eq (8). Degrees of freedom \(df\) for dependent t-interval
can be computed with:

\hypertarget{eq-9}{}
\[ df = n - 1 \tag{9}\]

Unlike independent t-test, in which two samples can have different
sample sizes \(n_1\) and \(n_2\), depedent t-test has only one sample
size, because the test subjects are compared to themselves.

Also note that dependent t-test assumes difference of test scores to be
normally distributed, not test scores of students themselves. But as
long as the test scores are normally distributed, the difference of test
scores will also be normally distributed due to the property of normal
distributions.

    \hypertarget{python_dep}{}

Pythonic Tip: Computing paired t-interval

Although Scipy supports computing t-statistic for dependent t-test, it
doesn't support a function that allows us to compute dependent
t-interval. We will have to write our own codes to compute it.

Don't forget to compute sample standard devaition, instead of population
standard deviation by setting ddof=1 as explained above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}190}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
          \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}191}]:} \PY{n}{x1} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1480}\PY{p}{,} \PY{l+m+mi}{1280}\PY{p}{,} \PY{l+m+mi}{890}\PY{p}{,} \PY{l+m+mi}{340}\PY{p}{,} \PY{l+m+mi}{1550}\PY{p}{,} \PY{l+m+mi}{1230}\PY{p}{,} \PY{l+m+mi}{1010}\PY{p}{,} \PY{l+m+mi}{1590}\PY{p}{,} \PY{l+m+mi}{1390}\PY{p}{,} \PY{l+m+mi}{980}\PY{p}{]}\PY{p}{)}
          \PY{n}{x2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1510}\PY{p}{,} \PY{l+m+mi}{1460}\PY{p}{,} \PY{l+m+mi}{1320}\PY{p}{,} \PY{l+m+mi}{700}\PY{p}{,} \PY{l+m+mi}{1550}\PY{p}{,} \PY{l+m+mi}{1420}\PY{p}{,} \PY{l+m+mi}{1340}\PY{p}{,} \PY{l+m+mi}{1570}\PY{p}{,} \PY{l+m+mi}{1500}\PY{p}{,} \PY{l+m+mi}{1300}\PY{p}{]}\PY{p}{)}
          
          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}                        \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
          \PY{n}{d\PYZus{}bar} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1} \PY{o}{\PYZhy{}} \PY{n}{x2}\PY{p}{)}            \PY{c+c1}{\PYZsh{} average of sample differences}
          \PY{n}{s\PYZus{}d} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{x1} \PY{o}{\PYZhy{}} \PY{n}{x2}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}       \PY{c+c1}{\PYZsh{} sample standard deviation of sample differences}
          \PY{n}{n} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}                         \PY{c+c1}{\PYZsh{} sample size}
          \PY{n}{df} \PY{o}{=} \PY{n}{n} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}                          \PY{c+c1}{\PYZsh{} degrees of freedom}
          \PY{n}{t} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{o}{/}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}    \PY{c+c1}{\PYZsh{} two\PYZhy{}tailed 95\PYZpc{} confidence t\PYZhy{}score}
          
          \PY{n}{lower} \PY{o}{=} \PY{n}{d\PYZus{}bar} \PY{o}{\PYZhy{}} \PY{n}{t} \PY{o}{*} \PY{n}{s\PYZus{}d} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{n}\PY{p}{)}
          \PY{n}{upper} \PY{o}{=} \PY{n}{d\PYZus{}bar} \PY{o}{+} \PY{n}{t} \PY{o}{*} \PY{n}{s\PYZus{}d} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{n}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}192}]:} \PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}192}]:} (-308.64567899681356, -77.35432100318641)
\end{Verbatim}
            
    The 95\% confidence interval of difference in means for dependent
samples does not have 0 within its interval. This means that the null
hypothesis, {\(H_0: \mu_1 - \mu_2 = 0\)} in figure (6), does not fall
within the interval. Instead, our estimation falls within the 2.5\%
outlier zone on the left, {\(H_1: \mu_1 - \mu_2 \neq 0\)}. We reject the
null hypothesis \(H_0\), and accept the alternate hypothesis \(H_1\). We
conclude that the sample means are significantly different. In the other
words, the tutoring program developed by the school had significant
impact on the SAT score of its students.

We can confirm this by running a formal hypothesis testing with
scipy.stats.ttest\_rel(). Note that this assumes dependent t-test.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}193}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}rel}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}193}]:} Ttest\_relResult(statistic=-3.7752930865755987, pvalue=0.004380623368522125)
\end{Verbatim}
            
    The computed pvalue=0.004 is smaller than the significance level of
alpha = 0.05, and therefore we reject the null hypothesis and accept the
alternate hypothesis, which is consistent with the conclusion drawn from
the confidence interval of difference in mean.

\textbf{Notes}: The above hypothesis testing answers the question of
"Did this tutoring program had a significant impact on the SAT scores of
students?". However, in cases like this, a more intuitive question is
"Did this tutoring program significantly improve the SAT scores of
students?" The former uses two-tailed test, and the latter uses
one-tailed test, and the procedures for them are a little different.

Checking results with R:

    \begin{verbatim}
<h4>Notes: Deciding which t-test to use</h4>
<p>Something</p>
\end{verbatim}

    \hypertarget{which_to_use}{}

\begin{verbatim}
<h4>Notes: Deciding which t-test to use</h4>
<p><u>Equal or unequal variance?</u></p>
<p style="padding-left: 1rem !important">Long story short, always assume unequal variance of samples when using t-test or constructing confidence interval of difference in means.</p>
<p style="padding-left: 1rem !important">Student's t-test is used for samples of equal variance, and Welch's t-test is used for samples of unequal variance. A natural question is, how do you know which test to use? While there exist techniques to check homogeneity of variances (f-test, Barlett's test, Levene's test), it is dangerous to run hypothesis testing for equality of variances to decide which t-test to use (student's t-test or Welch's t-test), because it increases Type I error (asserting something that is absent, false positive). This is shown by <a href="https://www.jstor.org/stable/2684403?seq=1#page_scan_tab_contents" target="_blank">Moser and Stevens (1992)</a> and <a href="https://onlinelibrary.wiley.com/doi/abs/10.1348/000711005X62576" target="_blank">Hayes and Cai (2010).</a></p>
<p style="padding-left: 1rem !important"><a href="https://link.springer.com/article/10.1007/s00362-009-0224-x" target="_blank">Kubinger, Rasch and Moder (2009)</a> argue that when the assumptions of normality and homogeneity of variances are met, Welch's t-test performs equally well, but outperforms when the assumptions are not met. <a href="https://academic.oup.com/beheco/article/17/4/688/215960" target="_blank">Ruxton (2006)</a> argues that the <i>"unequal variance t-test should always be used in preference to the Student's t-test"</i> (Note: what he means by "always" is assuming normality of distribution)</p>    
<p style="padding-left: 1rem !important">Also note that R uses Welch's t-test as the default for the <code>t.test()</code> function.</p>
<p><u>Independent (unpaired) or dependent (paired) samples?</u></p>
<p style="padding-left: 1rem !important">Paired t-test compares the same subjects at 2 different times . Unpaired t-test compares two different subjects.</p>
<p style="padding-left: 1rem !important">Samples are <i>independent (unpaired)</i> if one measurement is taken on different groups. For example in medical treament, group A is a control group, and is given a placebo with no medical effect. Group B is a test group, and receives a prescribed treatment with expected medical effect. Health check is applied on two groups, and the measurements are recorded. We say that the measurement from group A is independent from that of group B.<p>
<p style="padding-left: 1rem !important">Samples are <i>dependent (paired)</i> when repeated measures are taken on the same or related subjects. For example, there may be instances of the same patients being tested repeatedly - before and after receiving a particular treatment. In such cases, each patient is being used as a control sample against themselves. This method also applies to cases where the samples are related in some manner or have matching characteristics, like a comparative analysis involving children, parents or siblings.</p>
<p style="padding-left: 1rem !important">If you have a reason to believe that samples are correlated in any ways, it is recommended to use dependent test to reduce the effect of <a href="https://www.statisticshowto.datasciencecentral.com/experimental-design/confounding-variable/" target="_blank">confounding factors</a>.</p>
\end{verbatim}

    \hypertarget{conf_int_of_var}{}

\subsubsection{4.3. Confidence interval of
variance}\label{confidence-interval-of-variance}

Confidence interval of variance is used to estimate the population
variance from sample data and quantify the related uncertainty. C.I. of
variance is seldom used by itself, but rather used in conjunction with
f-test, which tests equality of variances of different populations.
Similar to how the confidence interval of difference in mean forms the
foundation of t-test, C.I. of variance forms the foundation of f-test.
In the field of statistics and machine learning, the equality of
variance is an important assumption when choosing which technique to
use. For example, when comparing the means of two samples, student's
t-test should not be used when you have a reason to believe that the two
samples have different variances. Personally, I found f-test to be
useful for the purpose of reading and understanding scientific papers,
as many of the papers I have read use f-test to test their hypothesis,
or use a variation of f-test for more advanced techniques. It is a
pre-requisite knowledge you need to know to understand the more advanced
techniques.

I mentioned that different statistics exhibit different distributions
above. When a sample data set originates from a normal distribution, its
sample means are normally distributed as shown in figure 4. On the other
hand, its sample variances are chi-square ({\(\chi^2\)}) distributed as
shown in figure ??? The curve is asymptotic, and never touches the
x-axis. The cumulative probabilty, which is often referred to as
"p-value" in hypothesis testing, propagates from the right (p-value=0)
to the left (p-value=1). For example, {\(\chi^2_{.975}=2.70\)} is in the
lower/left-tail and {\(\chi^2_{.025} = 19.02\)} is in the
upper/right-tail. When the samples follow a normal distribution, the
{\(\chi^2\)} statistic values can be plugged into eq (10) to compute the
confidence interval of variance.

\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_variance.png"></div>
<div class="col-12"><p class="image-description">Figure ???: 95% confidence interval of variance.</p></div>
\end{verbatim}

    \begin{verbatim}
<div class="solution_title">
    <p class="solution_title_string">Source Code For Figure (?)</p>
    <ul class="nav navbar-right panel_toolbox">
        <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
    </ul>
<div class="clearfix"></div>
</div>
<div class="solution_content">
    <pre>
        <code class="language-python">
            from scipy import stats
            import matplotlib.pyplot as plt
            import numpy as np

            df = 9
            x = np.linspace(-1, 28, 1000)
            y = stats.chi2.pdf(x, df, loc=0, scale=1)
            right_tail = stats.chi2.ppf(1 - 0.025, df) 
            left_tail = stats.chi2.ppf(1 - 0.975, df) 

            plt.style.use('seaborn-whitegrid')
            fig, ax = plt.subplots(figsize=(12, 5))

            ax.plot(x, y, c='black', label='Degrees of freedom = %d' % df)
            ax.set_xlabel('$\chi^2$', fontsize=17)
            ax.set_ylabel(r'Probability', fontsize=17)
            ax.set_title(r'$\chi^2\ \mathrm{Distribution}$, df = %d' % df, fontsize=17)
            ax.fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= left_tail), facecolor='grey')
            ax.fill_between(x, 0, y, where=(np.array(x) > left_tail) & (np.array(x) &lt; right_tail), facecolor='lightgrey')
            ax.fill_between(x, 0, y, where=(np.array(x) > right_tail) & (np.array(x) <= max(x)), facecolor='grey')
            ax.grid(False)

            ax.text(22, 0.008, '2.5% outlier', fontsize=13)
            ax.text(-2, 0.008, '2.5% outlier', fontsize=13)
            ax.text(0.5, 0.04, '$\chi^2_{.975} = %.2f$' % left_tail, fontsize=14, bbox=dict(boxstyle='round', facecolor='white'))
            ax.text(16.5, 0.015, '$\chi^2_{.025} = %.2f$' % right_tail, fontsize=14, bbox=dict(boxstyle='round', facecolor='white'))
            ax.text(20, 0.08, '$\chi^2_{.975} \leq \chi^2 \leq \chi^2_{.025}$', fontsize=16)
            ax.text(20, 0.06, '$2.70 \leq \chi^2 \leq 19.02$', fontsize=16)
            ax.text(6, 0.05, '95% confidence interval', fontsize=16)
            ax.text(6, 0.04, 'of variance', fontsize=16);
        </code>
    </pre>
</div>
\end{verbatim}

    \hypertarget{eq-10}{}
\[  \text{C.I.}_{\text{variance}}: \frac{(n-1)s^{2}}{\chi^{2}_{\frac{\alpha}{2}, df}} \leq \sigma^2 \leq \frac{(n-1)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2}, df}} \tag{10}\]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>$\sigma^2$<p></div>
    <div class="col-9"><p>: population variance<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$s^2$<p></div>
    <div class="col-9"><p>: sample variance<p></div>
</div>    
<div class="row">
    <div class="col-3">$\alpha$</div>
    <div class="col-9">: <a href="#">significance level</a></div>
</div>    
<div class="row">
    <div class="col-3"><p>$n$<p></div>
    <div class="col-9"><p>: number of samples<p></div>
</div>
<div class="row">
    <div class="col-3"><p>$df$<p></div>
    <div class="col-9"><p>: degrees of freedom.</div>
</div>    
<div class="row">
    <div class="col-3">$\chi^2$</div>
    <div class="col-9">: chi-squared statistic. Depends on $\alpha$ and $df$</div>
</div>   
\end{verbatim}

In confidence interval of variance, the degrees of freedom is:

\hypertarget{eq-11}{}
\[df = n - 1\]

Recall that the goal of any confidence interval is to estimate the
population parameter from a fraction of its samples due to the high cost
of obtaining measurement data of the entire data set, as explained in
Population vs Samples. You attempt to estimate the population variance
{\(\sigma^2\)} within the range of uncertainty with the sample variance
{\(s^2\)} obtained from a set of {n} samples that are "hopefully"
representative of the true population.

Confidence interval of variance assumes normality of samples, and is
very sensitive to the sample distribution's deviation from normality. In
case of non-normal sample distributions, you can either 1) transform the
distribution to normal distribution with Box-Cox transformation, or 2)
use non-parametric alternatives. For practitioners, I do not recommend
1) unless you really understand what you are doing, as the back
transformation process of Box-Cox transformation can be tricky.
Furthermore, it doesn't always result in successful transformation of
non-normal to normal distribution, as discussed below. I recommend to
use 2). If you have non-normal samples and your goal is to compute the
C.I. of variance, use bootstrap. If your goal is to check the equality
of variances of multiple sample data sets with hypothesis testing, use
Levene's test. Both are the non-parametric alternatives that does not
require normality of samples.

    \hypertarget{chi_square}{}

\begin{verbatim}
<h4>Notes: Chi-square $\chi^2$ distribution</h4>
<p>Chi-square <span style="font-size: 90% !important">$\chi^2$</span> distribution is a function of degrees of freedom <span style="font-size: 90% !important">$df$</span>. It is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing or in construction of confidence intervals.</p>
<p>It is used in the common chi-square goodness of fit test of an observed data set to a theoretical one. Let's say that there's a company that prints baseball cards. The company claims that 30% of the cards are rookies, 60% veterans but not All-Stars, and 10% are veteran All-Stars. Suppose that you purchased a deck of 100 cards. You found out that the card deck has 50 rookies, 45 veterans, and 5 All-Stars. Is this consistent with the company's claim? An answer to this question is explained in detail <a href="https://stattrek.com/chi-square-test/goodness-of-fit.aspx" target="_blank">here</a> using the chi-squared goodness of fit test. Note that the chi-square goodness of fit test does NOT require normality of data, but the chi-square test that checks if a variance equals a specified value DOES require normality of data.</p>
<p>When samples have a normal distribution, some of their statistics can be described by <span style="font-size: 90% !important">$\chi^2$</span> distributions. For example, the <a href="https://www.machinelearningplus.com/statistics/mahalanobis-distance/" target="_blank">Mahalanobis distance</a> follows <span style="font-size: 90% !important">$\chi^2$</span> distribution when samples are normally distributed, and can be used for multivariate outlier detection using <span style="font-size: 90% !important">$\chi^2$</span> hypothesis test. Variance of samples also follows <span style="font-size: 90% !important">$\chi^2$</span> distributions when samples are normally distributed, and can be used to construct the confidence interval of variances with <a href="">eq (???)</a>.</p>
<p>By the central limit theorem, a <span style="font-size: 90% !important">$\chi^2$</span> distribution converges to a normal distribution for large sample size <span style="font-size: 90% !important">$n$</span>. For many practical purposes, for <span style="font-size: 90% !important">$n$</span> > 50 the distribution is sufficiently close to a normal distribution for the difference to be ignored. Note that the sampling distribution of <span style="font-size: 90% !important">$ln(\chi^2)$</span> converges to normality much faster than the sampling distribution of <span style="font-size: 90% !important">$\chi^2$</span> as the logarithm removes much of the asymmetry. </p>    
<img class="admonition-image" style="border: 1px solid #ddd;" src="jupyter_images/chi_square.png"/>
<div class="solution_panel closed" style="margin-top: 20px;">
    <div class="solution_title solution_admonition">
        <p class="solution_title_string">Source Code For The Figure</p>
        <ul class="nav navbar-right panel_toolbox">
            <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
        </ul>
        <div class="clearfix"></div>
    </div>
    <div class="solution_content">
        <pre>
            <code class="language-python">
                from scipy import stats
                import matplotlib.pyplot as plt
                import numpy as np

                df_values = [1, 2, 6, 9]
                linestyles = ['-', '--', ':', '-.']
                x = np.linspace(-1, 20, 1000)

                fig, ax = plt.subplots(figsize=(6.6666666, 5))
                fig.tight_layout()
                plt.subplots_adjust(left=0.09, right=0.96, bottom=0.12, top=0.93)

                for df, ls in zip(df_values, linestyles):
                    ax.plot(x, stats.chi2.pdf(x, df, loc=0, scale=1), 
                            ls=ls, c='black', label=r'Degrees of freedom$=%i$' % df)

                ax.set_xlim(0, 10)
                ax.set_ylim(0, 0.5)
                ax.set_xlabel('$\chi^2$', fontsize=14)
                ax.set_ylabel(r'Probability', fontsize=14)
                ax.set_title(r'$\chi^2\ \mathrm{Distribution}$')
                ax.legend(loc='best', fontsize=11, framealpha=1, frameon=True)
            </code>
        </pre>
    </div>
</div>
\end{verbatim}

\hypertarget{one_tail_two_tail}{}

\begin{verbatim}
<h4>Notes: One-tail vs two-tail </h4>
<p>As you explore more about the field of statistics, you will encounter many scientific papers or articles using mostly upper/right-tailed f-test, instead of two-tailed or lower/left-tailed f-test. Why? That's because they don't have much practical use in real-life. This information is little beyond the scope of this article, but I still want to touch on it because the C.I. of variance forms the foundation of f-test. </p>
<p>When it comes to the test of variances, we often want to maintain a low variance than high variance, because the high variance is often related to high risk or instability. We are usually interested in knowing if a target population variance <span style="font-size: 90% !important">$\sigma^2$</span> is lower than a specified value <span style="font-size: 90% !important">$\sigma^2_0$</span>, not the other way around. This can be doen by using the upper/right-tailed hypothesis test, which is shown in the middle plot below. If the calculated statistic for f-test falls within the dark grey area, you reject your null hypothesis <span style="font-size: 90% !important">$H_0$</span>, and accept the alternate hypothesis <span style="font-size: 90% !important">$H_a$</span></p>
<img class="" style="border: 1px solid #ddd;" src="jupyter_images/two_tails.png"/>
<div class="solution_panel closed" style="margin-top: 20px;">
    <div class="solution_title solution_admonition">
        <p class="solution_title_string">Source Code For The Figure</p>
        <ul class="nav navbar-right panel_toolbox">
            <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
        </ul>
        <div class="clearfix"></div>
    </div>
    <div class="solution_content">
        <pre>
            <code class="language-python">
                from scipy import stats
                import matplotlib.pyplot as plt
                import numpy as np

                df = 9
                x = np.linspace(-1, 28, 1000)
                y = stats.chi2.pdf(x, df, loc=0, scale=1)

                # two-tailed
                two_right_tail = stats.chi2.ppf(1 - 0.025, df) 
                two_left_tail = stats.chi2.ppf(1 - 0.975, df)

                # one tailed
                one_right_tail = stats.chi2.ppf(1 - 0.05, df)
                one_left_tail = stats.chi2.ppf(1 - 0.95, df)


                plt.style.use('seaborn-whitegrid')
                fig, axes = plt.subplots(1, 3, figsize=(12, 3))

                for ax in axes:

                    ax.plot(x, y, c='black')
                    ax.grid(False)
                    ax.xaxis.set_major_formatter(plt.NullFormatter())
                    ax.yaxis.set_major_formatter(plt.NullFormatter())

                axes[0].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= two_left_tail), facecolor='grey')
                axes[0].fill_between(x, 0, y, where=(np.array(x) > two_left_tail) & (np.array(x) < two_right_tail), facecolor='lightgrey')
                axes[0].fill_between(x, 0, y, where=(np.array(x) > two_right_tail) & (np.array(x) <= max(x)), facecolor='grey')
                axes[0].set_title('Two-tailed', fontsize=20)
                axes[0].text(14, 0.08, r'$H_0: \sigma^2 = \sigma_0^2$', fontsize=20)
                axes[0].text(14, 0.057, r'$H_a: \sigma^2 \neq \sigma_0^2$', fontsize=20)

                axes[1].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) < one_right_tail), facecolor='lightgrey')
                axes[1].fill_between(x, 0, y, where=(np.array(x) > one_right_tail) & (np.array(x) <= max(x)), facecolor='grey')
                axes[1].set_title('Upper/right-tailed', fontsize=20)
                axes[1].text(14, 0.08, r'$H_0: \sigma^2 \leq \sigma_0^2$', fontsize=20)
                axes[1].text(14, 0.057, r'$H_a: \sigma^2 > \sigma_0^2$', fontsize=20)

                axes[2].fill_between(x, 0, y, where=(np.array(x) > min(x)) & (np.array(x) <= one_left_tail), facecolor='grey')
                axes[2].fill_between(x, 0, y, where=(np.array(x) > one_left_tail) & (np.array(x) <= max(x)), facecolor='lightgrey')
                axes[2].set_title('Lower/left-tailed', fontsize=20)
                axes[2].text(14, 0.08, r'$H_0: \sigma^2 \geq \sigma_0^2$', fontsize=20)
                axes[2].text(14, 0.057, r'$H_a: \sigma^2 < \sigma_0^2$', fontsize=20)

                fig.tight_layout()
            </code>
        </pre>
    </div>
</div>
\end{verbatim}

    \hypertarget{python_ci_var}{}

Pythonic Tip: Computing confidence interval of variance

Unfortunately, there's no Python or R library that computes the
confidence interval of variance. The fact that the pre-built function
does not exist both in Python and R suggests that the C.I. of variance
is seldom used. But as I mentioned before, the reason that I introduce
the C.I. of variance is because it forms the foundation of f-test, a
statistical hypothesis test that is widely used in scientific papers.

The C.I. of variance can be manually computed with eq (10). Don't forget
to compute sample variance, instead of population variance by setting
ddof=1 as explained above.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{n}{arr} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{8.69}\PY{p}{,} \PY{l+m+mf}{8.15}\PY{p}{,} \PY{l+m+mf}{9.25}\PY{p}{,} \PY{l+m+mf}{9.45}\PY{p}{,} \PY{l+m+mf}{8.96}\PY{p}{,} \PY{l+m+mf}{8.65}\PY{p}{,} \PY{l+m+mf}{8.43}\PY{p}{,} \PY{l+m+mf}{8.79}\PY{p}{,} \PY{l+m+mf}{8.63}\PY{p}{]}
        
        \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}               \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
        \PY{n}{n} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)}               \PY{c+c1}{\PYZsh{} sample sizes}
        \PY{n}{s2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{arr}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}   \PY{c+c1}{\PYZsh{} sample variance}
        \PY{n}{df} \PY{o}{=} \PY{n}{n} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}                 \PY{c+c1}{\PYZsh{} degrees of freedom}
        
        \PY{n}{upper} \PY{o}{=} \PY{p}{(}\PY{n}{n} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{*} \PY{n}{s2} \PY{o}{/} \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{n}{alpha} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}
        \PY{n}{lower} \PY{o}{=} \PY{p}{(}\PY{n}{n} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{)} \PY{o}{*} \PY{n}{s2} \PY{o}{/} \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{df}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} (0.07238029119542731, 0.5822533618682987)
\end{Verbatim}
            
    The output suggests that the 95\% confidence interval of variance is ---
{\(\text{C.I.}_{variance}: \,\, 0.072 < \sigma^2 < 0.582\)}

    \hypertarget{conf_int_of_other}{}

\subsubsection{4.3. Confidence interval of other statistics:
Bootstrap}\label{confidence-interval-of-other-statistics-bootstrap}

(Note: For those people who have web-development experience, this is not
CSS Bootstrap.)

I mentioned that different formulas are used to construct confidence
intervals of different statistics above. There are three problems with
computing the confidence interval of statistics with analytical
solutions:

\begin{verbatim}
<li><p>Not all statistics have formulas for their confidence intervals</p></li>
<li><p>Their formulas can be so convoluted, that it may be better to use numerical alternatives</p></li>
<li><p>You have to memorize their formulas</p></li>
\end{verbatim}

Bootstrapping is nice because it allows you to avoid these practical
concerns. For example, there are no formulas to compute the confidence
interval of covariance and median. On the other hand, regression
coefficient has its own formula for its confidence interval, but the
formulas get really messy in cases of multi-linear or non-linear
regression. Wouldn't it be nice if there's a "magic" that saves you from
all the math you have to worry about?

\begin{quote}
\textbf{Bootstrapping} is a statistical method for estimating the
sampling distribution of a statistic by sampling with replacement from
the original sample, most often with the purpose of estimating
confidence intervals of a population parameter like a mean, median,
proportion, correlation coefficient or regression coefficient.
\end{quote}

Constructing confidence interval with bootstrapping can be visually
understood with fig (?). Initially you have 5 samples
{\([8, 5, 4, 6, 2]\)} that you collected from an unknown population. You
randomly draw \(n=5\) samples from the original sample pool WITH
REPLACEMENT, and they become your \textbf{single bootstrap sample}. You
repeat this process \(r=6\) times to collect \textbf{multiple bootstrap
samples}. For each bootstrap sample, you run your functions to compute
the statistic of your interest: in this case, np.mean(single\_boot). Now
you have \(r=6\) sample means obtained from \(r\) bootstrap samples. You
can construct 95\% confidence interval of mean with percentile method:
np.percentile(mutliple\_boot\_means, 97.5)

\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_boot.png"></div>
<div class="col-12"><p class="image-description">Figure ???: Bootstrap 95% confidence interval of mean.</p></div>
\end{verbatim}

    \begin{verbatim}
<div class="solution_title">
    <p class="solution_title_string">Source Code For Figure (?)</p>
    <ul class="nav navbar-right panel_toolbox">
        <li><a class="collapse-link"><i class="fa fa-chevron-down"></i></a></li>
    </ul>
<div class="clearfix"></div>
</div>
<div class="solution_content">
    <pre>
        <code class="language-python">
            import matplotlib.pyplot as plt
            import numpy as np

            np.random.seed(42)
            arr = [8, 5, 4, 6, 2]

            ####################### Bootstrap ####################### 
            num_boot_samples = 1000
            def estimator(l):
                # statistic of interest; Ex: mean, median, variance ...
                return np.mean(l)

            boot = [estimator(np.random.choice(arr, len(arr))) for _ in range(num_boot_samples)]
            #########################################################

            plt.style.use('seaborn-whitegrid')
            fig, ax = plt.subplots(figsize=(10, 4))
            returns = ax.boxplot(boot, widths=0.5, whis=[2.5, 97.5],
                                 patch_artist=True, 
                                 boxprops=dict(linewidth=3.0, color='grey'),
                                 whiskerprops=dict(linewidth=3.0, color='grey'), vert=False,
                                 capprops=dict(linewidth=2.0, color='grey'),
                                 medianprops=dict(linewidth=2.0, color='yellow'))

            ax.set_aspect(1)
            ax.set_xlim(2.9, 7.1)
            ax.set_xlabel('x', fontsize=20)
            ax.yaxis.set_major_formatter(plt.NullFormatter())
            ax.set_title('Bootstrap 95% confidence interval of mean', fontsize=20)
        </code>
    </pre>
</div>
\end{verbatim}

    \hypertarget{detailed_bootstrap}{}

\begin{verbatim}
<h4>Notes: Technical details of Bootstrapping</h4>
<p>Something</p>
\end{verbatim}

Normal distributions cannot possibly capture major downside risks --
they lack ``fat tails. In Mandelbrot's view, analysis that attempts to
restrain risk -- or variance, or volatility, however you look at it --
to a finite probability distribution are misleading and dangerous.
Financial or economic theory based on the normal distribution, he wrote,
``is a house built on sand.'' To him, the normal distribution represents
``mild randomness,'' a condition Mandelbrot considered abnormal in
financial markets.

If you have a small sample, you have little power, end of story.

Heavey-tailed Bootstrap fails.

Bootstrapping is not a cure for small sample size =
https://stats.stackexchange.com/questions/112147/can-bootstrap-be-seen-as-a-cure-for-the-small-sample-size/112681\#112681

In the first case, as you mention in your comments, the Cauchy
distribution will cause problems in regards to comparing simple means,
as will any t distribution with degrees of freedom â‰¤2. This is because
the variance (in the true population) in these cases is infinite. The
validity of the bootstrap depends on the sampled data being
approximately distributed approximately the same as the true population.
But of course there will not be the case when the variance is infinite,
as the variance will be finite in any sample.

The practical implications of these are difficult to imagine, however.
In practice, we don't usually think of sampling data from a population
with an infinite variance.

A better rule of thumb is to consider that you need to have your sample
as a good representation of your population of interest. Hence the issue
with outliers: if you have very few, highly influential outliers in your
sample, you need to recognize that the distribution of your estimator is
very heavily influenced by the tails of the distribution, for which you
have very little data. Thus, what the bootstrap tells you about the
distribution of your estimator is likely to be inaccurate, as it is
highly dependent on an aspect of the population's distribution that you
empirically know very little about

https://stats.stackexchange.com/questions/172920/bootstrap-method-downsides

    linear - upper, preview

Pythonic - Confidence interval of non-linear regression coefficients -
here

    This is a widely used method for statistical inference in cases where
standard models are not available or are not appropriate. The method
involves repeated sampling with replacement of a dataset and calculating
the measure of interest on each sample. The repeated measure is then
used to determine the statistic of interest.

** pip install numpy==1.16.0 **

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}39}]:} \PY{k+kn}{import} \PY{n+nn}{requests}
         \PY{k+kn}{import} \PY{n+nn}{io}
         \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
         \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
         \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
         \PY{k+kn}{import} \PY{n+nn}{datetime}
         \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
         \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{resample}
         \PY{k+kn}{import} \PY{n+nn}{random}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}40}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{41}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    :param mean: mean}
         \PY{l+s+sd}{    :param std: standard deviation}
         \PY{l+s+sd}{    :return: simulated random gaussian noise}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{if} \PY{n}{dist} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{k}{return} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{std}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{skew\PYZus{}param} \PY{o}{=} \PY{l+m+mi}{100}
                 \PY{k}{return} \PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mf}{2.627}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{m}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{n}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{start\PYZus{}date}\PY{o}{=}\PY{n}{datetime}\PY{o}{.}\PY{n}{date}\PY{p}{(}\PY{l+m+mi}{2017}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skew}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    :param k: slope, increment in upwards/downwards trend (step size)}
         \PY{l+s+sd}{    :param m: y\PYZhy{}intercept}
         \PY{l+s+sd}{    :param n: number of samples}
         \PY{l+s+sd}{    :param start\PYZus{}date: start point in time\PYZhy{}series}
         \PY{l+s+sd}{    :return: }
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{xs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
             \PY{n}{ys} \PY{o}{=} \PY{p}{[}\PY{n}{k} \PY{o}{*} \PY{n}{x} \PY{o}{+} \PY{n}{m} \PY{o}{+} \PY{n}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{n}{dist}\PY{o}{=}\PY{n}{dist}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{ts} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{k}{return} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}
         
         \PY{n}{ys}\PY{p}{,} \PY{n}{ts} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight of elephant (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         
         \PY{n}{d} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ts}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ys}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{t}\PY{p}{:} \PY{n}{t}\PY{o}{.}\PY{n}{strftime}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{observations\PYZus{}by\PYZus{}month} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{month}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{month}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{groups} \PY{o}{=} \PY{n}{calc\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{groups}\PY{p}{,} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval (normal)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{lo\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{hi\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{months} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{k}{for} \PY{n}{month} \PY{o+ow}{in} \PY{n}{months}\PY{p}{:}
             \PY{n}{series} \PY{o}{=} \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{[}\PY{n}{month}\PY{p}{]}
             \PY{n}{bootstrapped\PYZus{}means} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} sample with replacement}
                 \PY{n}{bootstrap} \PY{o}{=} \PY{p}{[}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{series}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n}{series}\PY{p}{]}
                 \PY{n}{bootstrapped\PYZus{}means}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{bootstrap}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{)}
             \PY{n}{hi\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{months}\PY{p}{,} \PY{n}{lo\PYZus{}bounds}\PY{p}{,} \PY{n}{hi\PYZus{}bounds}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}
                             \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{ys}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}40}]:} (array([ 1.,  9., 23., 42., 37., 39., 36.,  9.,  3.,  1.]),
          array([ 736.0421313 ,  796.93114159,  857.82015187,  918.70916216,
                  979.59817244, 1040.48718273, 1101.37619301, 1162.2652033 ,
                 1223.15421358, 1284.04322387, 1344.93223415]),
          <a list of 10 Patch objects>)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_74_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_74_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
        \PY{k+kn}{import} \PY{n+nn}{datetime}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{random}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}36}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{41}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    :param mean: mean}
         \PY{l+s+sd}{    :param std: standard deviation}
         \PY{l+s+sd}{    :return: simulated random gaussian noise}
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{k}{if} \PY{n}{dist} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{k}{return} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{std}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{n}{skew\PYZus{}param} \PY{o}{=} \PY{l+m+mi}{100}
                 \PY{k}{return} \PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mf}{2.627}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{m}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{n}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{start\PYZus{}date}\PY{o}{=}\PY{n}{datetime}\PY{o}{.}\PY{n}{date}\PY{p}{(}\PY{l+m+mi}{2017}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skew}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{:}
             \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
         \PY{l+s+sd}{    :param k: slope, increment in upwards/downwards trend (step size)}
         \PY{l+s+sd}{    :param m: y\PYZhy{}intercept}
         \PY{l+s+sd}{    :param n: number of samples}
         \PY{l+s+sd}{    :param start\PYZus{}date: start point in time\PYZhy{}series}
         \PY{l+s+sd}{    :return: }
         \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
             \PY{n}{xs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
             \PY{n}{ys} \PY{o}{=} \PY{p}{[}\PY{n}{k} \PY{o}{*} \PY{n}{x} \PY{o}{+} \PY{n}{m} \PY{o}{+} \PY{n}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{n}{dist}\PY{o}{=}\PY{n}{dist}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{ts} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{k}{return} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}
         
         \PY{n}{ys}\PY{p}{,} \PY{n}{ts} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{normal}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight of elephant (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         
         \PY{k}{def} \PY{n+nf}{calc\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{)}\PY{p}{:}
             \PY{n}{groups} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{hi\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{group} \PY{o+ow}{in} \PY{n}{groups}\PY{p}{:}
                 \PY{n}{series} \PY{o}{=} \PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{[}\PY{n}{group}\PY{p}{]}
                 \PY{n}{mu}\PY{p}{,} \PY{n}{std}\PY{p}{,} \PY{n}{n} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{series}\PY{p}{)}
                 \PY{n}{lo\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{\PYZhy{}} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
                 \PY{n}{hi\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{+} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{k}{return} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{groups}
         
         \PY{n}{d} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ts}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ys}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{t}\PY{p}{:} \PY{n}{t}\PY{o}{.}\PY{n}{strftime}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{observations\PYZus{}by\PYZus{}month} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{month}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{month}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{groups} \PY{o}{=} \PY{n}{calc\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{groups}\PY{p}{,} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval (normal)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{ys}\PY{p}{)}
         
         \PY{n}{ys}\PY{p}{,} \PY{n}{ts} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{dist}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{skew}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight of elephant (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         
         \PY{k}{def} \PY{n+nf}{calc\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{)}\PY{p}{:}
             \PY{n}{groups} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{hi\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{group} \PY{o+ow}{in} \PY{n}{groups}\PY{p}{:}
                 \PY{n}{series} \PY{o}{=} \PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{[}\PY{n}{group}\PY{p}{]}
                 \PY{n}{mu}\PY{p}{,} \PY{n}{std}\PY{p}{,} \PY{n}{n} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{series}\PY{p}{)}
                 \PY{n}{lo\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{\PYZhy{}} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
                 \PY{n}{hi\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{+} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
             \PY{k}{return} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{groups}
         
         \PY{n}{d} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ts}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ys}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{t}\PY{p}{:} \PY{n}{t}\PY{o}{.}\PY{n}{strftime}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{observations\PYZus{}by\PYZus{}month} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{month}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{month}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{groups} \PY{o}{=} \PY{n}{calc\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{groups}\PY{p}{,} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval (normal)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{lo\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{hi\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{months} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{k}{for} \PY{n}{month} \PY{o+ow}{in} \PY{n}{months}\PY{p}{:}
             \PY{n}{series} \PY{o}{=} \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{[}\PY{n}{month}\PY{p}{]}
             \PY{n}{bootstrapped\PYZus{}means} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} sample with replacement}
                 \PY{n}{bootstrap} \PY{o}{=} \PY{p}{[}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{series}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n}{series}\PY{p}{]}
                 \PY{n}{bootstrapped\PYZus{}means}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{bootstrap}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{)}
             \PY{n}{hi\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{months}\PY{p}{,} \PY{n}{lo\PYZus{}bounds}\PY{p}{,} \PY{n}{hi\PYZus{}bounds}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,}
                             \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{ys}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}36}]:} (array([59., 59., 57., 20.,  3.,  0.,  1.,  0.,  0.,  1.]),
          array([1000.00220841, 1015.38831618, 1030.77442395, 1046.16053172,
                 1061.54663949, 1076.93274726, 1092.31885503, 1107.7049628 ,
                 1123.09107057, 1138.47717834, 1153.86328611]),
          <a list of 10 Patch objects>)
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_3.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_76_4.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{requests}
        \PY{k+kn}{import} \PY{n+nn}{io}
        \PY{k+kn}{import} \PY{n+nn}{pandas} \PY{k}{as} \PY{n+nn}{pd}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
        \PY{k+kn}{import} \PY{n+nn}{datetime}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{resample}
        
        
        \PY{k}{def} \PY{n+nf}{process\PYZus{}time}\PY{p}{(}\PY{n}{row}\PY{p}{)}\PY{p}{:}
        
            \PY{n}{call\PYZus{}received} \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{strptime}\PY{p}{(}\PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}time\PYZus{}received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{H:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{M:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{call\PYZus{}ended}    \PY{o}{=} \PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{strptime}\PY{p}{(}\PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{date\PYZus{}time\PYZus{}complete}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{+}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{T}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{H:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{M:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{time\PYZus{}ellapsed} \PY{o}{=} \PY{n}{call\PYZus{}ended} \PY{o}{\PYZhy{}} \PY{n}{call\PYZus{}received}
            
            \PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{str}\PY{p}{(}\PY{n}{call\PYZus{}received}\PY{p}{)}
            \PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Ended}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{str}\PY{p}{(}\PY{n}{call\PYZus{}ended}\PY{p}{)}
            \PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time Ellapsed}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{str}\PY{p}{(}\PY{n}{time\PYZus{}ellapsed}\PY{p}{)}
            \PY{n}{row}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time Ellapsed (minutes)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n+nb}{round}\PY{p}{(}\PY{n}{time\PYZus{}ellapsed}\PY{o}{.}\PY{n}{total\PYZus{}seconds}\PY{p}{(}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{60}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}
            \PY{k}{return} \PY{n}{row}
        
        \PY{k}{def} \PY{n+nf}{process\PYZus{}data}\PY{p}{(}\PY{p}{)}\PY{p}{:}
            
            \PY{n}{base\PYZus{}url} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{https://aegis4048.github.io/downloads/notebooks/sample\PYZus{}data/}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{filename} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{08c32c03\PYZhy{}9d88\PYZhy{}42a9\PYZhy{}b8a1\PYZhy{}f493a644b919\PYZus{}NRCEventReporting\PYZhy{}Calls\PYZhy{}2010.csv}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{data} \PY{o}{=} \PY{n}{requests}\PY{o}{.}\PY{n}{get}\PY{p}{(}\PY{n}{base\PYZus{}url} \PY{o}{+} \PY{n}{filename}\PY{p}{)}\PY{o}{.}\PY{n}{content}
            
            \PY{n}{df} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{read\PYZus{}csv}\PY{p}{(}\PY{n}{io}\PY{o}{.}\PY{n}{StringIO}\PY{p}{(}\PY{n}{data}\PY{o}{.}\PY{n}{decode}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{utf\PYZhy{}8}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}\PY{p}{)}
            \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{l+m+mi}{6000}\PY{p}{:} \PY{l+m+mi}{8000}\PY{p}{,} \PY{p}{:}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{n}{process\PYZus{}time}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{o}{.}\PY{n}{iloc}\PY{p}{[}\PY{p}{:}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{4}\PY{p}{:}\PY{p}{]}
            \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{to\PYZus{}datetime}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{H:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{M:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Ended}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{pd}\PY{o}{.}\PY{n}{to\PYZus{}datetime}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Ended}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n+nb}{format}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{ }\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{H:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{M:}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{S}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{n+nb}{str}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{[}\PY{p}{:} \PY{l+m+mi}{10}\PY{p}{]}\PY{p}{)}
            \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{sort\PYZus{}values}\PY{p}{(}\PY{n}{by} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
            \PY{n}{df} \PY{o}{=} \PY{n}{df}\PY{o}{.}\PY{n}{drop\PYZus{}duplicates}\PY{p}{(}\PY{n}{subset}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{keep}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
            \PY{k}{return} \PY{n}{df}
        
        \PY{n}{df} \PY{o}{=} \PY{n}{process\PYZus{}data}\PY{p}{(}\PY{p}{)}
        \PY{n}{duration} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time Ellapsed (minutes)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}
        \PY{n}{time} \PY{o}{=} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Call Received}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{values}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{k}{def} \PY{n+nf}{conf\PYZus{}int\PYZus{}mean}\PY{p}{(}\PY{n}{arr}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t\PYZhy{}interval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.05}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n}{mode} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t\PYZhy{}interval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{lo}\PY{p}{,} \PY{n}{hi} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{arr}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{arr}\PY{p}{)}\PY{p}{)}
                 \PY{k}{return} \PY{n}{lo}\PY{p}{,} \PY{n}{hi}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{arr}\PY{p}{)}
             \PY{k}{elif} \PY{n}{mode} \PY{o}{==} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:}
                 \PY{n}{boot} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{resample}\PY{p}{(}\PY{n}{arr}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{arr}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{]}\PY{p}{)}
                 \PY{n}{boot\PYZus{}means} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boot}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n}{lo} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{boot\PYZus{}means}\PY{p}{,} \PY{l+m+mi}{10}\PY{p}{)}
                 \PY{n}{hi} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{boot\PYZus{}means}\PY{p}{,} \PY{l+m+mi}{90}\PY{p}{)}\PY{p}{)} 
                 \PY{k}{return} \PY{n}{lo}\PY{p}{,} \PY{n}{hi}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boot\PYZus{}means}\PY{p}{)}
             \PY{k}{else}\PY{p}{:}
                 \PY{k}{raise} \PY{n}{e}
         
         \PY{n}{days} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n}{bins\PYZus{}by\PYZus{}days} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{day}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time Ellapsed (minutes)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{bins\PYZus{}by\PYZus{}days}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{day}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         
         \PY{n}{xt}\PY{p}{,} \PY{n}{y10}\PY{p}{,} \PY{n}{y50}\PY{p}{,} \PY{n}{y90} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{day} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{lo}\PY{p}{,} \PY{n}{mean}\PY{p}{,} \PY{n}{hi} \PY{o}{=} \PY{n}{conf\PYZus{}int\PYZus{}mean}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{p}{[}\PY{n}{day}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{xt}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{strptime}\PY{p}{(}\PY{n}{day}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{y10}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{lo}\PY{p}{)}
             \PY{n}{y50}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mean}\PY{p}{)}
             \PY{n}{y90}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{hi}\PY{p}{)}
             
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time}\PY{p}{,} \PY{n}{duration}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y10}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y50}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y90}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}yscale}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
         \PY{n}{xt}\PY{p}{,} \PY{n}{y10}\PY{p}{,} \PY{n}{y50}\PY{p}{,} \PY{n}{y90} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{day} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{lo}\PY{p}{,} \PY{n}{mean}\PY{p}{,} \PY{n}{hi} \PY{o}{=} \PY{n}{conf\PYZus{}int\PYZus{}mean}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{p}{[}\PY{n}{day}\PY{p}{]}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t\PYZhy{}interval}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{xt}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{strptime}\PY{p}{(}\PY{n}{day}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{y10}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{lo}\PY{p}{)}
             \PY{n}{y50}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mean}\PY{p}{)}
             \PY{n}{y90}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{hi}\PY{p}{)}
             
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time}\PY{p}{,} \PY{n}{duration}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y10}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y50}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y90}\PY{p}{)}
         \PY{n}{ax}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{o}{.}\PY{n}{set\PYZus{}yscale}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_78_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}44}]:} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{)}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}44}]:} (1000,)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}46}]:} \PY{n}{boot\PYZus{}mean}\PY{o}{.}\PY{n}{shape}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}46}]:} (1000,)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}51}]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}51}]:} 7.433125
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}56}]:} \PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n}{boot\PYZus{}mean}\PY{p}{)}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}56}]:} 7.391666666666667
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}42}]:} \PY{n}{days} \PY{o}{=} \PY{n+nb}{set}\PY{p}{(}\PY{n+nb}{list}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{)}
         \PY{n}{bins\PYZus{}by\PYZus{}days} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{day}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Days}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{df}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Time Ellapsed (minutes)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{bins\PYZus{}by\PYZus{}days}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{day}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         
         \PY{n}{xt}\PY{p}{,} \PY{n}{y10}\PY{p}{,} \PY{n}{y50}\PY{p}{,} \PY{n}{y90} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{,} \PY{p}{[}\PY{p}{]}
         
         \PY{n}{lo\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{n}{hi\PYZus{}bounds} \PY{o}{=} \PY{p}{[}\PY{p}{]}
         \PY{k}{for} \PY{n}{day} \PY{o+ow}{in} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{series} \PY{o}{=} \PY{n}{bins\PYZus{}by\PYZus{}days}\PY{p}{[}\PY{n}{day}\PY{p}{]}
             \PY{n}{bootstrapped\PYZus{}means} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{:}
                 \PY{c+c1}{\PYZsh{} sample with replacement}
                 \PY{n}{bootstrap} \PY{o}{=} \PY{p}{[}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{series}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n}{series}\PY{p}{]}
                 \PY{n}{bootstrapped\PYZus{}means}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{bootstrap}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{2.5}\PY{p}{)}\PY{p}{)}
             \PY{n}{hi\PYZus{}bounds}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{percentile}\PY{p}{(}\PY{n}{bootstrapped\PYZus{}means}\PY{p}{,} \PY{l+m+mf}{97.5}\PY{p}{)}\PY{p}{)}    
             
             \PY{n}{lo}\PY{p}{,} \PY{n}{mean}\PY{p}{,} \PY{n}{hi} \PY{o}{=} \PY{n}{conf\PYZus{}int\PYZus{}mean}\PY{p}{(}\PY{n}{series}\PY{p}{,} \PY{n}{mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{bootstrap}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{n}{xt}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{p}{[}\PY{n}{datetime}\PY{o}{.}\PY{n}{datetime}\PY{o}{.}\PY{n}{strptime}\PY{p}{(}\PY{n}{day}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m\PYZhy{}}\PY{l+s+si}{\PYZpc{}d}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{]}\PY{p}{)}
             \PY{n}{y10}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{lo}\PY{p}{)}
             \PY{n}{y50}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mean}\PY{p}{)}
             \PY{n}{y90}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{hi}\PY{p}{)}
             
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{time}\PY{p}{,} \PY{n}{duration}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{tick\PYZus{}params}\PY{p}{(}\PY{n}{axis}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{rotation}\PY{o}{=}\PY{l+m+mi}{30}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{lo\PYZus{}bounds}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{y50}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{xt}\PY{p}{,} \PY{n}{hi\PYZus{}bounds}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}yscale}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
                 \PY{n}{boot} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{resample}\PY{p}{(}\PY{n}{series}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{]}\PY{p}{)}
                 \PY{c+c1}{\PYZsh{} 1000 x 1 array}
                 \PY{n}{boot\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boot}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
                 \PY{n}{lo} \PY{o}{=} \PY{n}{boot\PYZus{}mean}\PY{p}{[}\PY{l+m+mi}{50}\PY{p}{]}
                 \PY{n}{hi} \PY{o}{=} \PY{n}{boot\PYZus{}mean}\PY{p}{[}\PY{l+m+mi}{950}\PY{p}{]}
                 
                 \PY{n}{bootstrap} \PY{o}{=} \PY{p}{[}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n}{series}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n}{series}\PY{p}{]}
                 \PY{n}{bootstrapped\PYZus{}means}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{bootstrap}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_83_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{resample}
         
         \PY{c+c1}{\PYZsh{} 1000 x 12 array}
         \PY{n}{boot} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{resample}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{p}{[}\PY{n}{day}\PY{p}{]}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n+nb}{len}\PY{p}{(}\PY{n}{bins\PYZus{}by\PYZus{}days}\PY{p}{[}\PY{n}{day}\PY{p}{]}\PY{p}{)}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} 1000 x 1 array}
         \PY{n}{boot\PYZus{}mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boot}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}222}]:} \PY{k}{def} \PY{n+nf}{lognorm\PYZus{}params}\PY{p}{(}\PY{n}{mode}\PY{p}{,} \PY{n}{stddev}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    Given the mode and std. dev. of the log\PYZhy{}normal distribution, this function}
          \PY{l+s+sd}{    returns the shape and scale parameters for scipy\PYZsq{}s parameterization of the}
          \PY{l+s+sd}{    distribution.}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{p} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{poly1d}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{o}{\PYZhy{}}\PY{p}{(}\PY{n}{stddev}\PY{o}{/}\PY{n}{mode}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
              \PY{n}{r} \PY{o}{=} \PY{n}{p}\PY{o}{.}\PY{n}{roots}
              \PY{n}{sol} \PY{o}{=} \PY{n}{r}\PY{p}{[}\PY{p}{(}\PY{n}{r}\PY{o}{.}\PY{n}{imag} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{r}\PY{o}{.}\PY{n}{real} \PY{o}{\PYZgt{}} \PY{l+m+mi}{0}\PY{p}{)}\PY{p}{]}\PY{o}{.}\PY{n}{real}
              \PY{n}{shape} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{log}\PY{p}{(}\PY{n}{sol}\PY{p}{)}\PY{p}{)}
              \PY{n}{scale} \PY{o}{=} \PY{n}{mode} \PY{o}{*} \PY{n}{sol}
              \PY{k}{return} \PY{n}{shape}\PY{p}{,} \PY{n}{scale}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}223}]:} \PY{n}{sigma}\PY{p}{,} \PY{n}{scale} \PY{o}{=} \PY{n}{lognorm\PYZus{}params}\PY{p}{(}\PY{l+m+mf}{0.0001}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}225}]:} \PY{n}{sigma}\PY{p}{,} \PY{n}{scale}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}225}]:} (array([2.62830846]), array([0.10002501]))
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}227}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mf}{2.627}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}227}]:} 1.1761971327350966
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}103}]:} \PY{k}{def} \PY{n+nf}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{std}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    :param mean: mean}
          \PY{l+s+sd}{    :param std: standard deviation}
          \PY{l+s+sd}{    :return: simulated random gaussian noise}
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{k}{return} \PY{n}{random}\PY{o}{.}\PY{n}{gauss}\PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{std}\PY{p}{)}
          
          \PY{k}{def} \PY{n+nf}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{m}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{n}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{start\PYZus{}date}\PY{o}{=}\PY{n}{datetime}\PY{o}{.}\PY{n}{date}\PY{p}{(}\PY{l+m+mi}{2017}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{:}
              \PY{l+s+sd}{\PYZdq{}\PYZdq{}\PYZdq{}}
          \PY{l+s+sd}{    :param k: slope, increment in upwards/downwards trend (step size)}
          \PY{l+s+sd}{    :param m: y\PYZhy{}intercept}
          \PY{l+s+sd}{    :param n: number of samples}
          \PY{l+s+sd}{    :param start\PYZus{}date: start point in time\PYZhy{}series}
          \PY{l+s+sd}{    :return: }
          \PY{l+s+sd}{    \PYZdq{}\PYZdq{}\PYZdq{}}
              \PY{n}{xs} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
              \PY{n}{ys} \PY{o}{=} \PY{p}{[}\PY{n}{k} \PY{o}{*} \PY{n}{x} \PY{o}{+} \PY{n}{m} \PY{o}{+} \PY{n}{add\PYZus{}gaussian\PYZus{}noise}\PY{p}{(}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
              \PY{n}{ts} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
              \PY{k}{return} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}
          
          \PY{n}{ys}\PY{p}{,} \PY{n}{ts} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{p}{)}
          
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Date}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight of elephant (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}103}]:} Text(0,0.5,'Weight of elephant (kg)')
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_89_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}104}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{ys}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_90_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}91}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}92}]:} \PY{n}{temp} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{s}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{temp}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{yscale}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{log}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_92_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{k}{def} \PY{n+nf}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{m}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{start\PYZus{}date}\PY{o}{=}\PY{n}{datetime}\PY{o}{.}\PY{n}{date}\PY{p}{(}\PY{l+m+mi}{2017}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{xs} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
             \PY{n}{ys} \PY{o}{=} \PY{p}{[}\PY{n}{k} \PY{o}{*} \PY{n}{x} \PY{o}{+} \PY{n}{m} \PY{o}{+} \PY{n}{random}\PY{o}{.}\PY{n}{gauss}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{sigma}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{ts} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)} \PY{o}{*} \PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{x\PYZus{}scale} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{500}\PY{p}{)} \PY{c+c1}{\PYZsh{} for plotting}
             \PY{n}{t\PYZus{}scale} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{x\PYZus{}scale}\PY{p}{]}
             \PY{k}{return} \PY{n}{xs}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}\PY{p}{,} \PY{n}{x\PYZus{}scale}\PY{p}{,} \PY{n}{t\PYZus{}scale}
         
         \PY{n}{xs}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}\PY{p}{,} \PY{n}{x\PYZus{}scale}\PY{p}{,} \PY{n}{t\PYZus{}scale} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}113}]:} \PY{n}{data} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{skewnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_94_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{k}{def} \PY{n+nf}{plot\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{)}\PY{p}{:}
             \PY{n}{groups} \PY{o}{=} \PY{n+nb}{list}\PY{p}{(}\PY{n+nb}{sorted}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}group}\PY{o}{.}\PY{n}{keys}\PY{p}{(}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{lo\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{hi\PYZus{}bound} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{n}{means} \PY{o}{=} \PY{p}{[}\PY{p}{]}
             \PY{k}{for} \PY{n}{group} \PY{o+ow}{in} \PY{n}{groups}\PY{p}{:}
                 \PY{n}{series} \PY{o}{=} \PY{n}{observations\PYZus{}by\PYZus{}group}\PY{p}{[}\PY{n}{group}\PY{p}{]}
                 \PY{n}{mu}\PY{p}{,} \PY{n}{std}\PY{p}{,} \PY{n}{n} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n}{numpy}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{series}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{series}\PY{p}{)}
                 \PY{n}{lo\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{\PYZhy{}} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
                 \PY{n}{hi\PYZus{}bound}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu} \PY{o}{+} \PY{l+m+mf}{1.96}\PY{o}{*}\PY{n}{std}\PY{o}{*}\PY{n}{n}\PY{o}{*}\PY{o}{*}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.5}\PY{p}{)}
                 \PY{n}{means}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{mu}\PY{p}{)}
             \PY{n}{plt}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{groups}\PY{p}{,} \PY{n}{lo\PYZus{}bound}\PY{p}{,} \PY{n}{hi\PYZus{}bound}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.2}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Confidence interval (normal)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
             \PY{k}{return} \PY{n}{means}\PY{p}{,} \PY{n}{groups}
             
         \PY{k}{def} \PY{n+nf}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{n}{k}\PY{o}{=}\PY{l+m+mi}{200}\PY{p}{,} \PY{n}{m}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{sigma}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{,} \PY{n}{n}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{start\PYZus{}date}\PY{o}{=}\PY{n}{datetime}\PY{o}{.}\PY{n}{date}\PY{p}{(}\PY{l+m+mi}{2017}\PY{p}{,} \PY{l+m+mi}{7}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}\PY{p}{:}
             \PY{n}{xs} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{n}\PY{p}{,} \PY{n}{endpoint}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
             \PY{n}{ys} \PY{o}{=} \PY{p}{[}\PY{n}{k}\PY{o}{*}\PY{n}{x} \PY{o}{+} \PY{n}{m} \PY{o}{+} \PY{n}{random}\PY{o}{.}\PY{n}{gauss}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{sigma}\PY{p}{)} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{ts} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{xs}\PY{p}{]}
             \PY{n}{x\PYZus{}scale} \PY{o}{=} \PY{n}{numpy}\PY{o}{.}\PY{n}{linspace}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{,} \PY{l+m+mi}{500}\PY{p}{)} \PY{c+c1}{\PYZsh{} for plotting}
             \PY{n}{t\PYZus{}scale} \PY{o}{=} \PY{p}{[}\PY{n}{start\PYZus{}date} \PY{o}{+} \PY{n}{datetime}\PY{o}{.}\PY{n}{timedelta}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{o}{*}\PY{l+m+mi}{365} \PY{k}{for} \PY{n}{x} \PY{o+ow}{in} \PY{n}{x\PYZus{}scale}\PY{p}{]}
             \PY{k}{return} \PY{n}{xs}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}\PY{p}{,} \PY{n}{x\PYZus{}scale}\PY{p}{,} \PY{n}{t\PYZus{}scale}
         
         \PY{n}{xs}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{ts}\PY{p}{,} \PY{n}{x\PYZus{}scale}\PY{p}{,} \PY{n}{t\PYZus{}scale} \PY{o}{=} \PY{n}{generate\PYZus{}time\PYZus{}series}\PY{p}{(}\PY{p}{)}
         \PY{n}{d} \PY{o}{=} \PY{n}{pandas}\PY{o}{.}\PY{n}{DataFrame}\PY{p}{(}\PY{p}{\PYZob{}}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{x}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{xs}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ts}\PY{p}{,} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{:} \PY{n}{ys}\PY{p}{\PYZcb{}}\PY{p}{)}
         \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]} \PY{o}{=} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{t}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{o}{.}\PY{n}{apply}\PY{p}{(}\PY{k}{lambda} \PY{n}{t}\PY{p}{:} \PY{n}{t}\PY{o}{.}\PY{n}{strftime}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{Y\PYZhy{}}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{m}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{plt}\PY{o}{.}\PY{n}{scatter}\PY{p}{(}\PY{n}{ts}\PY{p}{,} \PY{n}{ys}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{s}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         \PY{n}{observations\PYZus{}by\PYZus{}month} \PY{o}{=} \PY{p}{\PYZob{}}\PY{p}{\PYZcb{}}
         \PY{k}{for} \PY{n}{month}\PY{p}{,} \PY{n}{y} \PY{o+ow}{in} \PY{n+nb}{zip}\PY{p}{(}\PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Month}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,} \PY{n}{d}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}\PY{p}{:}
             \PY{n}{observations\PYZus{}by\PYZus{}month}\PY{o}{.}\PY{n}{setdefault}\PY{p}{(}\PY{n}{month}\PY{p}{,} \PY{p}{[}\PY{p}{]}\PY{p}{)}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{y}\PY{p}{)}
         \PY{n}{means}\PY{p}{,} \PY{n}{groups} \PY{o}{=} \PY{n}{plot\PYZus{}confidence\PYZus{}interval}\PY{p}{(}\PY{n}{observations\PYZus{}by\PYZus{}month}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{ylabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Weight of elephant (kg)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}21}]:} <matplotlib.legend.Legend at 0x253601d3470>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_95_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}116}]:} \PY{n}{right\PYZus{}tail} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.025}\PY{p}{,} \PY{n}{df}\PY{p}{)} 
          \PY{n}{left\PYZus{}tail} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.975}\PY{p}{,} \PY{n}{df}\PY{p}{)} 
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}117}]:} \PY{n}{right\PYZus{}tail}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}117}]:} 19.02276779864163
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}115}]:} \PY{n}{left\PYZus{}tail\PYZus{}975} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.975}\PY{p}{,} \PY{n}{df}\PY{p}{)} 
\end{Verbatim}


    \textbf{Variance follows chi-squared distribution, if samples are
normally distributed.}

\textbf{P-value propagates toward left}

\textbf{Equation, depends on alpha, degree of freedom}

Means can be the same, but their std can be different. One team is
pretty consistent from game to game, but the other team fluctuates a
lot. Which team has the smaller score variance? -\textgreater{} plays a
very important role in quality assurance and operations management

Variance is chi-square distributed. But how is it related to the actual
data we collect?

\[\chi^2 = \frac{(n-1)s^2}{\sigma^2}\]

\[\chi_{.975}^{2} < \chi^2 < \chi_{.025}^{2}\]

\[ \text{C.I.}_{\text{variance}}: \frac{(n-1)s^{2}}{\chi^{2}_{\frac{\alpha}{2}}} \leq \sigma^2 \leq \frac{(n-1)s^{2}}{\chi^{2}_{1-\frac{\alpha}{2}}}\]

stats.chi2.ppf(0.975, 11) = 21.92

We are estimating population variance.

This volatility is one way of interpreting risk. The trade-off of risk
vs. reward.

Used in conjunction with more advanced tasks.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{n}{conf\PYZus{}pinkman} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mi}{18} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{96.2}\PY{p}{,} \PY{n}{scale}\PY{o}{=} \PY{l+m+mi}{4} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{18}\PY{p}{)}\PY{p}{)}
        \PY{n}{conf\PYZus{}white} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{l+m+mi}{21} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mf}{99.1}\PY{p}{,} \PY{n}{scale}\PY{o}{=} \PY{l+m+mi}{3} \PY{o}{/} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{21}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{plt}\PY{o}{.}\PY{n}{style}\PY{o}{.}\PY{n}{use}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{seaborn\PYZhy{}whitegrid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{2}\PY{p}{)}\PY{p}{)}
        
        \PY{n}{ax}\PY{o}{.}\PY{n}{errorbar}\PY{p}{(}\PY{l+m+mf}{99.1}\PY{p}{,} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{xerr}\PY{o}{=}\PY{p}{(}\PY{n}{conf\PYZus{}white}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{conf\PYZus{}white}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{,}
                    \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{markersize}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{capsize}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mr. White}\PY{l+s+se}{\PYZbs{}\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{grey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{errorbar}\PY{p}{(}\PY{l+m+mf}{96.2}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{xerr}\PY{o}{=}\PY{p}{(}\PY{n}{conf\PYZus{}pinkman}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]} \PY{o}{\PYZhy{}} \PY{n}{conf\PYZus{}pinkman}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{)} \PY{o}{/} \PY{l+m+mi}{2}\PY{p}{,}
                    \PY{n}{fmt}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{o}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{markersize}\PY{o}{=}\PY{l+m+mi}{8}\PY{p}{,} \PY{n}{capsize}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{label}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Mr. Pinkman}\PY{l+s+se}{\PYZbs{}\PYZsq{}}\PY{l+s+s1}{s}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{k}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}ylim}\PY{p}{(}\PY{o}{\PYZhy{}}\PY{l+m+mf}{0.6}\PY{p}{,} \PY{l+m+mf}{1.6}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}betweenx}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{conf\PYZus{}white}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{p}{,} \PY{n}{conf\PYZus{}pinkman}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{]}\PY{p}{,} \PY{n}{facecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lightgrey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{alpha}\PY{o}{=}\PY{l+m+mf}{0.3}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{legend}\PY{p}{(}\PY{n}{loc}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{best}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{11}\PY{p}{,} \PY{n}{framealpha}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{frameon}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{set\PYZus{}xlabel}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Purity (}\PY{l+s+s1}{\PYZpc{}}\PY{l+s+s1}{)}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{fontsize}\PY{o}{=}\PY{l+m+mi}{12}\PY{p}{)}
        \PY{n}{ax}\PY{o}{.}\PY{n}{yaxis}\PY{o}{.}\PY{n}{set\PYZus{}major\PYZus{}formatter}\PY{p}{(}\PY{n}{plt}\PY{o}{.}\PY{n}{NullFormatter}\PY{p}{(}\PY{p}{)}\PY{p}{)}
        \PY{n}{fig}\PY{o}{.}\PY{n}{tight\PYZus{}layout}\PY{p}{(}\PY{p}{)}\PY{p}{;}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_100_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsection{Robustness of variance to
non-normality}\label{robustness-of-variance-to-non-normality}

Standard deviations are a bit more sensitive to outliers than means are
-\/- when you put in an outlier, you tend to push the one-sample
t-statistic toward 1 or -1.

https://stats.stackexchange.com/questions/193117/why-is-high-positive-kurtosis-problematic-for-hypothesis-tests

\subsubsection{Difference of the confidence interval constructed with
t-test vs bootstrap for skewed
data}\label{difference-of-the-confidence-interval-constructed-with-t-test-vs-bootstrap-for-skewed-data}

    \subsection{Robustness of confidence intervals to
non-normality}\label{robustness-of-confidence-intervals-to-non-normality}

All of the discussions above assume normality of data set. Conclusions
drawn from confidence intervals and hypothesis testing may be
inaccurate, or completely wrong if the underlying assumptions are not
met. This sections discusses why the assumption of normality is
important, robustness of statistical estimations in regards to deviation
from normality, and non-parametric alternatives.

    \hypertarget{central_tendency}{}

\subsubsection{Measuring central tendency of
distributions}\label{measuring-central-tendency-of-distributions}

We discussed how to compute confidence interval of mean and confidence
interval of difference in means. But have you thought about why
statisticians bother specifically about the means? Often times the
ultimate goal is not to compute a mean of a distribution, but to compute
a measure of central tendency of a distribution.

A measure of central tendency is a single value that attempts to
describe a set of data by identifying the central position within that
set of data. The mean is the measure of central tendency that you are
the most familiar with, but there are others, such as the median and the
mode.

\textbf{Point estimation}

Mean is not a good measure of central tendency when there is a sign of
deviation from normality, which can be characterized by skewness
(asymmetry) and kurtosis (heavy-tails). Consider the following figures:

\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_non_norm_means.png"></div>
<div class="col-12"><p class="image-description">Figure ??: Central tendency of distributions</p></div>
\end{verbatim}

In figure (??) (a), there is no skewness, making the distribution
symmetric. In this case, mean is a good measure of central tendency,
along with median and mode --- they are all equivalent. You can compute
its confidence interval of mean using eq (1), and use it as a measure of
central tendency, thanks to the symmetry of the distribution.

However, when distributions have non-zero skewness, as in figure (??)
(b), the assumption of normality is violated. Depending on how bad the
asymmetry is, you can still use eq (1), because confidence interval of
mean is robust to mild asymmetry. However, if a distribution has
non-negligible skewness, interval computed with eq (1) introduces bias
to one side of a distribution.

Although there exists non-parametric alternatives like Bootstrap and
credible interval, you may want to take a step back and reconsider the
purpose of your estimation. Are you really interested in the mean, or
the central tendency of your distribution? In a case like figure (??)
(b), perhaps you are more interested in the median, as it's a better
measure of central tendency of asymmetric distributions.

Visualize your distribution to see what your true interest is.

\textbf{Comparison of distributions}

Similar idea applies when you want to compare two distributions. Let's
say that you want to decide if two samples came from the same population
by comparing their confidence interval of means. Consider the following
figure of two non-normal sample distributions:

\begin{verbatim}
<div class="col"><img src="jupyter_images/conf_int_non_norms_overlap.png"></div>
<div class="col-12"><p class="image-description">Figure ??: Confidencen interval of means for non-normal distributions</p></div>
\end{verbatim}

Note that the {95\% confidence interval of means} in figure (??) are
asymmetric about their respective sample means, because they are
computed with non-parametric alternatives. Since there is an overlap of
the two intervals, you can conclude that the sample means are not
significantly different. Furthermore, even the variances of the samples
are the same; I generated the plots so that they have the same
variances.

Now, you know that the samples have equal means and variances within the
range of uncertainty. Can you conclude that the two samples came from
the same population? Clearly not, because their central locations are
far apart from each other. Their central tendencies are better described
by their medians than their means.

In this case, if you are using confidence confidence interval of means
and variances to check if two samples came from the same population,
your approach is wrong. This kind of approach assumes normality of data.
Any approach that makes a certain assumption of data fails when that
assumption is violated.

If your goal is to find out if the two samples originated from the same
population, you may want to use non-parametric alternatives, such as
Mann-Whitney test or Kruskall-Wallis test; they are geared towards
comparing central tendency of distributions, not means or variances.

    \subsubsection{Robustness of t-test}\label{robustness-of-t-test}

T-test loses some of its statistical power when there is a sign of
deviation from normality, which can be characterized by skewness
(asymmetry) and kurtosis (heavy-tails). Why? It's because t-test is a
test of means, and means are not good measures of central tendency of
asymmetric distributions, as I explained here.

Let's say that you want to decide if two samples came from different
populations by comparing the confidence interval of means. Consider the
following figure:

-\/-\/-\/-\/-\/-\/-\/- image -\/-\/-\/-\/-\/-\/-\/-

T-test is fairly resistant to moderate deviations from normality ---
visualize your distribution to test this.

To be specific, it is sensitive to asymmetry of the distribution, but
not much to kurtosis. As a rule of thumb (not a law of nature),
inference about means is sensitive to skewness and inference about
variances is sensitive to kurtosis

asymptotic expansion

https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless/30053\#30053

T-test is fairly resistent to moderate deviations

https://www.johndcook.com/blog/2018/05/11/two-sample-t-test/

That said, the t-test can tolerate moderate skewness and
heavy-tailedness (though in the latter case your actual significance
levels will tend to be lower than the nominal ð›¼).

Non-parametric alternatives are 95\% powerful of t-test, when data are
normal.

    \section{Bootstrapping}\label{bootstrapping}

convergence in the Monte Carlo integration.

\textbf{Clarifiy Bootstrap resamples (r) vs original samples (n)}

https://yanirseroussi.com/2019/01/08/hackers-beware-bootstrap-sampling-may-be-harmful/

Unfortunately, this method is just not accurate enough for small sample
sizes. Quoting Hesterberg (emphasis mine):

"The sample sizes needed for different intervals to satisfy the
``reasonably accurate'' (off by no more than 10\% on each side)
criterion are: n â‰¥ 101 for the bootstrap t, 220 for the
skewness-adjusted t statistic, 2,235 for expanded percentile, 2,383 for
percentile, 4,815 for ordinary t (which I have rounded up to 5,000
above), 5,063 for t with bootstrap standard errors and something over
8,000 for the reverse percentile method."

In practice, implementing some of the more accurate bootstrap methods is
difficult (especially those not described here), and people should use a
package rather than attempt this themselves.

In short, make sure you're using an accurate method for estimating
confidence intervals when dealing with sample sizes of less than a few
thousand values

Accurate bootstrap estimates require a large number of resamples. Many
code snippets use 1,000 resamples, probably because it looks like a
large number. However, seeming large isn't enough. Quoting Hesterberg
again:

For both the bootstrap and permutation tests, the number of resamples
needs to be 15,000 or more, for 95\% probability that simulation-based
one-sided levels fall within 10\% of the true values, for 95\% intervals
and 5\% tests. I recommend r = 10,000 for routine use, and more when
accuracy matters.

We want decisions to depend on the data, not random variation in the
Monte Carlo implementation. We used r = 500,000 in the Verizon project.

That's right, half a million resamples! Accuracy mattered in the Verizon
case, as the results of the analysis determined whether large penalties
were paid or not. In short, use at least 10-15,000 resamples to be safe.
Don't use 1,000.

https://stats.stackexchange.com/questions/246726/size-of-bootstrap-samples

The bootstrap method is only useful if your sample follows more or less
(read exactly) the same distribution as the original population. In
order to be certain this is the case you need to make your sample size
large enough. But what is large enough?

I took interest in this question because I saw the word bootstrap and I
have written books on the bootstrap. Also people often ask "How many
bootstrap samples do I need to get a good Monte Carlo approximation to
the bootstrap result?" My suggested answer to that question is to keep
increasing the size until you get convergence. No one number fits all
problems.

Now if the sample size is very small-\/-\/-say 4-\/-\/-the bootstrap may
not work just because the set of possible bootstrap samples is not rich
enough. In my book or Peter Hall's book this issue of too small a sample
size is discussed. But this number of distinct bootstrap samples gets
large very quickly. So this is not an issue even for sample sizes as
small as 8.

While the basic bootstrap makes no assumption about the underlying
distribution of the data, it is not assumption-free. For example, when
dealing with correlated data points from a time series, using the basic
bootstrapping approach is wrong because it assumes that the data points
are independent. Instead, a block bootstrap should be used -- see the
ARCH package for some implementation examples. In addition,
bootstrapping doesn't solve problems with the underlying sampling
approach. For example, the data sample may not be representative of the
population because of its small size, or there may be selection biases
and measurement errors.

https://erikbern.com/2018/10/08/the-hackers-guide-to-uncertainty-estimates.html

Another approach that can be useful is bootstrapping. It allows you do
compute the same statistics without memorizing any formulas.
Bootstrapping is nice because it lets you dodge any questions about what
probability distribution the data is generated from. It's basically plug
and play, and works on almost everything, though it can be a bit slow.
Be aware though that there's a danger zone of bootstrapping. My
understanding is that bootstrapping will converge towards the correct
estimates as the number of samples goes to infinity, but if you're
working with small samples, you can get really wonky results. I
generally never trust bootstrapping for anything less than say 50
samples, and you probably shouldn't do that either.

\textbf{Time-Series Bootstrapping}

https://stats.stackexchange.com/questions/25706/how-do-you-do-bootstrapping-with-time-series-data

The resampling method introduced in Efron (1979) was designed for i.i.d.
univariate data but is easily extended to multivariate data. As
discussed in . If x1,â‹…â‹…â‹…,xn is a sample of vectors, to maintain the
covariance structure of the data in the sample. It is not immediately
obvious whether one can resample a time series x1,x2,â‹…â‹…â‹…,xn. A time
series is essentially a sample of size 1 from a stochastic process.
Resampling a sample is original sample, so one learns nothing by
resampling. Therefore, resampling of a time series requires new ideas.

Model-based resampling is easily adopted to time series. The resamples
are obtained by simulating the time series model. For example, if the
model is ARIMA(p,d,q), then the resamples of an ARIMA(p, q) model with
MLEs (from the differenced series) of the autoregressive and moving
average coefficients and the noise variance. The resamples are the
sequences of partial sum of the simulated ARIMA(p, q) process.

Model-free resampling of time series is accomplished by block
resampling, also called block bootstrap

The idea is to break the series into roughly equal-length blocks of
consecutive observations, to resample the block with replacement, and
then to paste the blocks together.

Bootstrapping requires data to be

    \subsubsection{Robustness of confidence interval of
variance}\label{robustness-of-confidence-interval-of-variance}

\subsection{Non-parametric
alternatives}\label{non-parametric-alternatives}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
        
        \PY{n}{stats}\PY{o}{.}\PY{n}{chi2}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mf}{0.025}\PY{p}{,} \PY{l+m+mi}{11}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} 3.8157482522361
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}177}]:} \PY{n}{x1} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{12.9}\PY{p}{,} \PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{7.4}\PY{p}{,} \PY{l+m+mf}{7.0}\PY{p}{,} \PY{l+m+mf}{10.5}\PY{p}{,} \PY{l+m+mf}{11.9}\PY{p}{,} \PY{l+m+mf}{7.1}\PY{p}{,} \PY{l+m+mf}{9.9}\PY{p}{,} \PY{l+m+mf}{14.4}\PY{p}{,} \PY{l+m+mf}{11.3}\PY{p}{]}
          \PY{n}{x2} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{6.9}\PY{p}{,} \PY{l+m+mf}{10.9}\PY{p}{,} \PY{l+m+mf}{11.0}\PY{p}{,} \PY{l+m+mf}{10.1}\PY{p}{,} \PY{l+m+mf}{5.3}\PY{p}{,} \PY{l+m+mf}{7.5}\PY{p}{,} \PY{l+m+mf}{10.3}\PY{p}{,} \PY{l+m+mf}{9.2}\PY{p}{,} \PY{l+m+mf}{8.8}\PY{p}{]}
          
          \PY{n}{alpha} \PY{o}{=} \PY{l+m+mf}{0.05}                                                       \PY{c+c1}{\PYZsh{} significance level = 5\PYZpc{}}
          \PY{n}{n1}\PY{p}{,} \PY{n}{n2} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}                                          \PY{c+c1}{\PYZsh{} sample sizes}
          \PY{n}{s1}\PY{p}{,} \PY{n}{s2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{,} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{x2}\PY{p}{,} \PY{n}{ddof}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}                    \PY{c+c1}{\PYZsh{} sample variances}
          \PY{n}{df} \PY{o}{=} \PY{p}{(}\PY{n}{s1}\PY{o}{/}\PY{n}{n1} \PY{o}{+} \PY{n}{s2}\PY{o}{/}\PY{n}{n2}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2} \PY{o}{/} \PY{p}{(}\PY{p}{(}\PY{n}{s1}\PY{o}{/}\PY{n}{n1}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{o}{/}\PY{p}{(}\PY{n}{n1}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{+} \PY{p}{(}\PY{n}{s2}\PY{o}{/}\PY{n}{n2}\PY{p}{)}\PY{o}{*}\PY{o}{*}\PY{l+m+mi}{2}\PY{o}{/}\PY{p}{(}\PY{n}{n2}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}  \PY{c+c1}{\PYZsh{} degrees of freedom}
          \PY{n}{t} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{ppf}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{n}{alpha}\PY{p}{,} \PY{n}{df}\PY{p}{)}   
          
          \PY{n}{lower} \PY{o}{=} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{n}{t} \PY{o}{*} \PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{+} \PY{l+m+mi}{1} \PY{o}{/} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)} \PY{o}{*} \PY{n}{s}
          
          \PY{n}{lower}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}177}]:} -0.49379818720606283
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{skewnorm}
        \PY{k+kn}{from} \PY{n+nn}{matplotlib} \PY{k}{import} \PY{n}{pyplot} \PY{k}{as} \PY{n}{plt}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        \PY{k+kn}{import} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats}
        \PY{n}{a}\PY{o}{=}\PY{l+m+mi}{100}
        \PY{n}{data}\PY{o}{=} \PY{n}{skewnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{a}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}91}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{median}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
         \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
         
         \PY{n}{ax}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.8381086010164204
0.7177974832846665

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}91}]:} <matplotlib.lines.Line2D at 0x1a2310f2e8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_110_2.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}321}]:} \PY{o}{\PYZpc{}}\PY{k}{matplotlib} inline
          
          \PY{n}{data} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{skewnorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}
          \PY{n}{density} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{gaussian\PYZus{}kde}\PY{p}{(}\PY{n}{noise}\PY{p}{)}
          \PY{n}{mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}
          \PY{n}{median} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{median}\PY{p}{(}\PY{n}{data}\PY{p}{)}
          
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
          \PY{n}{n}\PY{p}{,} \PY{n}{x}\PY{p}{,} \PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{ax}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+m+mi}{50}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{edgecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{black}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}  
          \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{density}\PY{p}{(}\PY{n}{x}\PY{p}{)}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{red}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
          \PY{n}{ax}\PY{o}{.}\PY{n}{axvline}\PY{p}{(}\PY{n}{median}\PY{p}{,} \PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{green}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}321}]:} <matplotlib.lines.Line2D at 0x1a2fb65dd8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_111_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}322}]:} \PY{n}{lower}\PY{p}{,} \PY{n}{upper} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
          \PY{n}{mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{mean}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(0.7714451906907809, 0.8480109036057044)
0.8097280471482426

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}323}]:} \PY{n}{incre} \PY{o}{=} \PY{l+m+mi}{5}
          \PY{n}{temp}\PY{p}{,} \PY{n}{lmbda} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{boxcox}\PY{p}{(}\PY{n}{data} \PY{o}{+} \PY{n}{incre}\PY{p}{)}
          
          \PY{n}{lower\PYZus{}b}\PY{p}{,} \PY{n}{upper\PYZus{}b} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{temp}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{temp}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{temp}\PY{p}{)}\PY{p}{)}
          
          \PY{n}{lower\PYZus{}b}\PY{p}{,} \PY{n}{upper\PYZus{}b} \PY{o}{=} \PY{n}{inv\PYZus{}boxcox}\PY{p}{(}\PY{n}{lower\PYZus{}b}\PY{p}{,} \PY{n}{lmbda}\PY{p}{)}\PY{p}{,} \PY{n}{inv\PYZus{}boxcox}\PY{p}{(}\PY{n}{upper\PYZus{}b}\PY{p}{,} \PY{n}{lmbda}\PY{p}{)}
          \PY{n}{mean\PYZus{}b} \PY{o}{=} \PY{n}{inv\PYZus{}boxcox}\PY{p}{(}\PY{n}{mean}\PY{p}{,} \PY{n}{lmbda}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}324}]:} \PY{n+nb}{print}\PY{p}{(}\PY{p}{(}\PY{n}{lower\PYZus{}b} \PY{o}{\PYZhy{}} \PY{n}{incre}\PY{p}{,} \PY{n}{upper\PYZus{}b} \PY{o}{\PYZhy{}} \PY{n}{incre}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(0.6609200748348814, 0.7272585524637014)

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}330}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{temp}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
          \PY{n}{prob} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{probplot}\PY{p}{(}\PY{n}{temp}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{p}{,} \PY{n}{plot}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_115_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_115_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}290}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{special} \PY{k}{import} \PY{n}{inv\PYZus{}boxcox}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}292}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{resample}
          
          \PY{n}{boots} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{resample}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{]}\PY{p}{)}
          \PY{n}{a} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boots}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{a}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{a}\PY{p}{[}\PY{l+m+mi}{95}\PY{p}{]}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{a}\PY{p}{[}\PY{l+m+mi}{50}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
0.7418236409304393 0.796416903031344
0.7675645387929715

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}331}]:} \PY{c+c1}{\PYZsh{} sample data generation}
          \PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{seed}\PY{p}{(}\PY{l+m+mi}{42}\PY{p}{)}
          \PY{n}{data} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{n}{s}\PY{o}{=}\PY{l+m+mf}{0.5}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{,} \PY{n}{size}\PY{o}{=}\PY{l+m+mi}{1000}\PY{p}{)}\PY{p}{)}
          
          \PY{c+c1}{\PYZsh{} fit lognormal distribution}
          \PY{n}{shape}\PY{p}{,} \PY{n}{loc}\PY{p}{,} \PY{n}{scale} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
          \PY{n}{pdf\PYZus{}lognorm} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{lognorm}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{shape}\PY{p}{,} \PY{n}{loc}\PY{p}{,} \PY{n}{scale}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}333}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{pdf\PYZus{}lognorm}\PY{p}{)}
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
          
          \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{density}\PY{o}{=}\PY{k+kc}{True}\PY{p}{,} \PY{n}{bins}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{auto}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}\PY{p}{;}
          \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{p}{)}
          \PY{n}{prob} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{probplot}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{dist}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{p}{,} \PY{n}{plot}\PY{o}{=}\PY{n}{ax}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_119_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_119_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}334}]:} \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{resample}
          
          \PY{n}{boots} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{p}{[}\PY{n}{resample}\PY{p}{(}\PY{n}{data}\PY{p}{,} \PY{n}{replace}\PY{o}{=}\PY{k+kc}{True}\PY{p}{)} \PY{k}{for} \PY{n}{\PYZus{}} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{l+m+mi}{100}\PY{p}{)}\PY{p}{]}\PY{p}{)}
          \PY{n}{a} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{boots}\PY{p}{,} \PY{n}{axis}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{a}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{,} \PY{n}{a}\PY{p}{[}\PY{l+m+mi}{95}\PY{p}{]}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{a}\PY{p}{[}\PY{l+m+mi}{50}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
1117.553360410937 1168.6710419552019
1142.8236697715936

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}335}]:} \PY{n}{lower}\PY{p}{,} \PY{n}{upper} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{data}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{data}\PY{p}{)}\PY{p}{)}
          \PY{n}{mean} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{data}\PY{p}{)}
          
          \PY{n+nb}{print}\PY{p}{(}\PY{p}{(}\PY{n}{lower}\PY{p}{,} \PY{n}{upper}\PY{p}{)}\PY{p}{)}
          \PY{n+nb}{print}\PY{p}{(}\PY{n}{mean}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
(1103.6610566132003, 1180.2601663391847)
1141.9606114761925

    \end{Verbatim}

    \subsection{Measure of central
tendency}\label{measure-of-central-tendency}

The median is usually preferred to other measures of central tendency
when your data set is skewed (i.e., forms a skewed distribution) or you
are dealing with ordinal data.

It is usually inappropriate to use the mean in such situations where
your data is skewed. You would normally choose the median or mode, with
the median usually preferred.

    \subsection{Robustness of confidence interval to
non-normality}\label{robustness-of-confidence-interval-to-non-normality}

All of the discussions above assume normality of data set. Conclusions
drawn from confidence intervals and hypothesis testing may be
inaccurate, or completely wrong if the underlying assumptions are not
met. This sections discusses why the assumption of normality is
important, robustness of statistical estimations in regards to deviation
from normality, and non-parametric alternatives.

\subsubsection{Measuring central tendency of
distributions}\label{measuring-central-tendency-of-distributions}

We discussed how to compute confidence interval of mean and confidence
interval of difference in means. But have you thought about why
statisticians bother specifically about the means? The ultimate goal is
not to compute a mean of distributions, but to compute a measure of
central tendency of distributions.

A measure of central tendency is a single value that attempts to
describe a set of data by identifying the central position within that
set of data. As such, measures of central tendency are sometimes called
measures of central location. The mean is the measure of central
tendency that you are the most familiar with, but there are others, such
as the median and the mode.

\subsubsection{Robustness of confidence interval of
mean}\label{robustness-of-confidence-interval-of-mean}

\subsubsection{Robustness of confidence interval of
variance}\label{robustness-of-confidence-interval-of-variance}

\subsection{Non-parametric
alternatives}\label{non-parametric-alternatives}

    \begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item ~
  \subsection{Is it for point
  estimation?}\label{is-it-for-point-estimation}
\item
  Is it for hypothesis testing?
\item
\end{enumerate}

The t tends to have reasonably good power relative to the Mann-Whitney
for light-tailed distributions ... and can have really bad power for
heavy-tailed ones. Skewness tends to be compounded with heavy tails

T-test is robust to mild skewness, that is, mild non-normality.

have to note that all of the knowledge I just imparted is somewhat
obsolete; now that we have computers, we can do better than t-tests. As
Frank notes, you probably want to use Wilcoxon tests anywhere you were
taught to run a t-test.

    \begin{verbatim}
<h4>Notes: Robustness of confidence interval to non-normality</h4>
<p>t-test is fairly resistent to moderate deviations from normality
    
    If distribution is unacceptably not normal, use confidence interval of median, but only if your goal is to compare central tendency. 
\end{verbatim}

Overall, the two sample t-test is reasonably power-robust to symmetric
non-normality

When the two samples are mildly skew in the same direction, the
one-tailed t-test is no longer unbiased.

Confidence interval of mean can stand some violation of normality. But
confidecne interval of variance is very susceptible.

\begin{verbatim}
<p></p>
\end{verbatim}

    \section{Sample Sizes}\label{sample-sizes}

Illustrate confidence intervals of every stats, with previously given s,
mu.

    This comparison helps to determine how likely the difference between the
means occurred by chance or whether the data sets really have intrinsic
differences. The t-test questions whether the difference between the
groups represents a true difference in the study or if it is likely a
meaningless statistical difference.

    \subsubsection{Python confidence interval of difference in
means}\label{python-confidence-interval-of-difference-in-means}

https://stackoverflow.com/questions/31768464/confidence-interval-for-t-test-difference-between-means-in-python/34516534\#34516534

    \section{Power of non-parametric methods on normal
data}\label{power-of-non-parametric-methods-on-normal-data}

    \section{Bootstrapping}\label{bootstrapping}

CLT does not apply to how many resampling you do. It applied only on the
original dataset.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}29}]:} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{y}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}29}]:} 8.181868181125685e-05
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}30}]:} \PY{n}{np}\PY{o}{.}\PY{n}{var}\PY{p}{(}\PY{n}{y2}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}30}]:} 8.181868181125686e-05
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}22}]:} \PY{n}{x} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
         \PY{n}{y} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{beta}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{a}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{b}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         
         \PY{n}{x2} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{arange} \PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,} \PY{l+m+mi}{100}\PY{p}{,} \PY{l+m+mf}{0.1}\PY{p}{)}
         \PY{n}{y2} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{beta}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{a}\PY{o}{=}\PY{l+m+mi}{5}\PY{p}{,} \PY{n}{b}\PY{o}{=}\PY{l+m+mi}{2}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{l+m+mi}{100}\PY{p}{)}
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{6}\PY{p}{)}\PY{p}{)}
         
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{x}\PY{p}{,} \PY{n}{y}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{y2}\PY{p}{,} \PY{n}{linewidth}\PY{o}{=}\PY{l+m+mi}{4}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}22}]:} [<matplotlib.lines.Line2D at 0x1116c29b0>,
          <matplotlib.lines.Line2D at 0x1a2562d198>]
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_133_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \section{One-tail vs Two-tail}\label{one-tail-vs-two-tail}

Customer: wants at least 355 ml in water
\[\text{Quantity of water} \geq 355 ml\]

Manufacturer: exactly 355 ml \[\text{Quantity of water} = 355 ml\]

Collect 50 bottles, and test our assumption

\section{1 sample vs 2 samples}\label{sample-vs-2-samples}

Am I testing assumption, or the status quo that already exists?
-\textgreater{} 1 sample? Am I testing new claim or assertion beyoned
what I already know? -\textgreater{} 2 samples?

    \section{Frequently Asked Questions}\label{frequently-asked-questions}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is significance level?
\item
  What is confidence level?
\item
  What is standard error?
\item
  What is distribution score?
\item
  What should I do if the sample data is not normally distributed?
\end{enumerate}

\subsubsection{CI of lognormal
distribution}\label{ci-of-lognormal-distribution}

https://amstat.tandfonline.com/doi/full/10.1080/10691898.2005.11910638\#.XQvVFtNKhQI

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}25}]:} \PY{n}{x1} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{12.9}\PY{p}{,} \PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{7.4}\PY{p}{,} \PY{l+m+mf}{7.0}\PY{p}{,} \PY{l+m+mf}{10.5}\PY{p}{,} \PY{l+m+mf}{11.9}\PY{p}{,} \PY{l+m+mf}{7.1}\PY{p}{,} \PY{l+m+mf}{9.9}\PY{p}{,} \PY{l+m+mf}{14.4}\PY{p}{,} \PY{l+m+mf}{11.3}\PY{p}{]}
         \PY{n}{x2} \PY{o}{=} \PY{p}{[}\PY{l+m+mf}{10.2}\PY{p}{,} \PY{l+m+mf}{6.9}\PY{p}{,} \PY{l+m+mf}{10.9}\PY{p}{,} \PY{l+m+mf}{11.0}\PY{p}{,} \PY{l+m+mf}{10.1}\PY{p}{,} \PY{l+m+mf}{5.3}\PY{p}{,} \PY{l+m+mf}{7.5}\PY{p}{,} \PY{l+m+mf}{10.3}\PY{p}{,} \PY{l+m+mf}{9.2}\PY{p}{,} \PY{l+m+mf}{8.8}\PY{p}{]}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}26}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x1}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{x1}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}26}]:} (8.461873578892417, 12.058126421107586)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}27}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mi}{1} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.05}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{x2}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{stats}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{x2}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}27}]:} (7.663208497074507, 10.376791502925492)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}28}]:} \PY{n}{stats}\PY{o}{.}\PY{n}{ttest\PYZus{}ind}\PY{p}{(}\PY{n}{x1}\PY{p}{,} \PY{n}{x2}\PY{p}{,} \PY{n}{equal\PYZus{}var}\PY{o}{=}\PY{k+kc}{False}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}28}]:} Ttest\_indResult(statistic=1.245268949149111, pvalue=0.23018336828903668)
\end{Verbatim}
            
    A confidence interval's width is due entirely to sampling error. As the
sample size approaches the entire population, the width of the
confidence interval approaches zero.

    Confidence interval has the following general form:

\hypertarget{eq-1}{}
\[ \text{C. I.} = \text{point estimate} \pm (\text{distribution score} \times \text{Standard Error}) \tag{1} \]

\begin{verbatim}
<div class="row eq-terms-where">where</div>
<div class="row">
    <div class="col-3"><p>-$D^2$<p></div>
    <div class="col-9"><p> description description description description description description description description description<p></div>
</div>
<div class="row">
    <div class="col-3">-$D^2$</div>
    <div class="col-9">description</div>
</div>    
\end{verbatim}

The decision makers always wants to know the uncertainty related to your
estimation.

This tutorial includes explanation of idea behind C.I., complications
that arise when sample data is not normally distributed and solutions
for them. For those who don't want to spend more than 2 minutes reading,
I included a quick Python code snippets that can generate C.I. for any
type of distribution for any type of statistic.

\textbf{Central Limit Theorem may not always apply}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Nonnormal data, variance known: If the population distribution is not
  normal and the sample is 'large enough', then XÂ¯ is approximately
  normal and the same formula provides an approximate 95\% CI. The rule
  that nâ‰¥30 is 'large enough' is unreliable here. If the population
  distribution is heavy-tailed, then XÂ¯ may not have a distribution that
  is close to normal (even if nâ‰¥30). The 'Central Limit Theorem', often
  provides reasonable approximations for moderate values of n, but it is
  a limit theorem, with guaranteed results only as nâ†’âˆž.
\end{enumerate}

Many statistical techniques assume that sample data is normally
distributed or Gaussian-like (Ex: t-distribution), and different
techniques should be considered for non-normal data set.

\textbf{Correct vs. Wrong vs. Useful}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{)}
        \PY{n+nb}{print}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
3.375
1.4086784586980805

    \end{Verbatim}

    \subsubsection{Extension of Confidence Interval with
Bootstrapping}\label{extension-of-confidence-interval-with-bootstrapping}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{bayes\PYZus{}mvs}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{n}{bayes\PYZus{}mvs}\PY{p}{(}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{8}\PY{p}{,}\PY{l+m+mi}{5}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:} (Mean(statistic=4.0, minmax=(2.39878883101482, 5.60121116898518)),
         Variance(statistic=8.0, minmax=(2.8435061229431486, 18.45571858443238)),
         Std\_dev(statistic=2.691341356821504, minmax=(1.686269884372946, 4.296011939512317)))
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{k+kn}{from} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{import} \PY{n}{truncnorm}
         \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
         \PY{o}{\PYZpc{}}\PY{k}{matplotlib} notebook
         
         \PY{k}{def} \PY{n+nf}{get\PYZus{}truncated\PYZus{}normal}\PY{p}{(}\PY{n}{mean}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{sd}\PY{o}{=}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{low}\PY{o}{=}\PY{o}{\PYZhy{}}\PY{l+m+mi}{3}\PY{p}{,} \PY{n}{upp}\PY{o}{=}\PY{l+m+mi}{7}\PY{p}{)}\PY{p}{:}
             \PY{k}{return} \PY{n}{truncnorm}\PY{p}{(}
                 \PY{p}{(}\PY{n}{low} \PY{o}{\PYZhy{}} \PY{n}{mean}\PY{p}{)} \PY{o}{/} \PY{n}{sd}\PY{p}{,} \PY{p}{(}\PY{n}{upp} \PY{o}{\PYZhy{}} \PY{n}{mean}\PY{p}{)} \PY{o}{/} \PY{n}{sd}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{mean}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{sd}\PY{p}{)}
         
         
         \PY{n}{X1} \PY{o}{=} \PY{n+nb}{sorted}\PY{p}{(}\PY{n}{get\PYZus{}truncated\PYZus{}normal}\PY{p}{(}\PY{p}{)}\PY{o}{.}\PY{n}{rvs}\PY{p}{(}\PY{l+m+mi}{10000}\PY{p}{)}\PY{p}{)}
         \PY{n}{mean}\PY{p}{,} \PY{n}{std} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{fit}\PY{p}{(}\PY{n}{X1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{l+m+mi}{0}\PY{p}{)}
         \PY{n}{pdf\PYZus{}norm} \PY{o}{=} \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{pdf}\PY{p}{(}\PY{n}{X1}\PY{p}{,} \PY{n}{mean}\PY{p}{,} \PY{n}{std}\PY{p}{)}
         
         
         \PY{n}{fig}\PY{p}{,} \PY{n}{ax} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{subplots}\PY{p}{(}\PY{n}{figsize}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{8}\PY{p}{,} \PY{l+m+mi}{4}\PY{p}{)}\PY{p}{)}
         \PY{n}{ax}\PY{o}{.}\PY{n}{plot}\PY{p}{(}\PY{n}{X1}\PY{p}{,} \PY{n}{pdf\PYZus{}norm}\PY{p}{)}
         
         \PY{n}{ax}\PY{o}{.}\PY{n}{fill\PYZus{}between}\PY{p}{(}\PY{n}{X1}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{,} \PY{n}{pdf\PYZus{}norm}\PY{p}{,} 
                         \PY{n}{where}\PY{o}{=}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X1}\PY{p}{)}\PY{o}{\PYZgt{}}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X1}\PY{p}{)}\PY{o}{\PYZlt{}}\PY{o}{=}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} 
                         \PY{n}{facecolor}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lightgrey}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{c+c1}{\PYZsh{} ax.fill\PYZus{}betweenx(pdf\PYZus{}norm, 2, x2=7, interpolate=True)}
\end{Verbatim}


    
    \begin{verbatim}
<IPython.core.display.Javascript object>
    \end{verbatim}

    
    
    \begin{verbatim}
<IPython.core.display.HTML object>
    \end{verbatim}

    
\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}11}]:} <matplotlib.collections.PolyCollection at 0x25efc5ea5c0>
\end{Verbatim}
            
    Note: This interval is only exact when the population distribution is
normal. For large samples from other population distributions, the
interval is approximately correct by the Central Limit Theorem.

    \subsubsection{\texorpdfstring{What is confidence level
\(1 - \alpha\)?}{What is confidence level 1 - \textbackslash{}alpha?}}\label{what-is-confidence-level-1---alpha}

Confidence level is the chance that the statistic value of your interest
lies within the interval. A common choice of confidence level include

    \section{Simulation Ideas}\label{simulation-ideas}

https://stats.stackexchange.com/questions/38967/how-robust-is-the-independent-samples-t-test-when-the-distributions-of-the-sampl

    \subsection{Practical Application - Bayes
Approximation}\label{practical-application---bayes-approximation}

    \section{Kruskal-Wallis}\label{kruskal-wallis}

Hence, in terms of original values, the Kruskal-Wallis is more general
than a comparison of means: it tests whether the probability that a
random observation from each group is equally likely to be above or
below a random observation from another group. The real data quantity
that underlies that comparison is neither the differences in means nor
the difference in medians, (in the two sample case) it is actually the
median of all pairwise differences - the between-sample Hodges-Lehmann
difference.

    \section{Non-Parametric Methods}\label{non-parametric-methods}

Very robust under normality too.

Non-parametric tests (as Wilcoxon-Mann-Whitney) do not rely on a
specific distiribution, but implicitly rely on equal variances: under H0
are all samples from the same population.

\section{Mann-Whitney}\label{mann-whitney}

https://stats.stackexchange.com/questions/31361/some-questions-about-two-sample-comparisons

scipy.stats.mannwhitneyu: It returns a "One-sided p-value assuming a
asymptotic normal distribution" . Why is it assuming a normal
distribution? Should't this test work on any underlying distribution?

I think the sentence is referring to the large sample (asymptotic)
distribution of the test statistic, not the data. As you can see here,
the Mann-Whitney U test statistic has an approximate normal distribution
when the sample size is large.

There's a difference between Mann-Whiteny, and Wilcoxon

Mann-Whitney U test works fine with continuous data, I would even say it
works best with them because you would avoid ties.

When you have heavier-tailed than normal data, it's also typically more
powerful than the t-test

The median is usually preferred to other measures of central tendency
when your data set is skewed (i.e., forms a skewed distribution) or you
are dealing with ordinal data.

In no way will the difference in sample sizes adversely affect the
Mann-Whitney-Wilcoxon test.

Valid only when more than 20 samples

FYI, Wikipedia adds that, for large samples, ð‘ˆ is approximately normally
distributed. Given all these values, one can also calculate the effect
size Î·2,

https://stats.stackexchange.com/questions/67204/what-exactly-does-a-non-parametric-test-accomplish-what-do-you-do-with-the-res/67210\#67210

This link says that Welch t-test should always be used over Mann-Whitney
if your goal is to compare central tendency of two distributions:

https://stats.stackexchange.com/questions/313471/always-use-welch-t-test-unequal-variances-t-test-instead-of-student-t-or-mann

\section{Hotelling's T stats}\label{hotellings-t-stats}

https://courses.lumenlearning.com/boundless-statistics/chapter/the-t-test/

    \section{Normality testing}\label{normality-testing}

take a test on the distribution, e.g. Kolmogorov-Smirnov-test. After
that you know whether you have a normal or not. then you need to test
neither skewness nor curtosis.

The values for asymmetry and kurtosis between -2 and +2 are considered
acceptable in order to prove normal univariate distribution (George \&
Mallery, 2010)

    \section{F-test}\label{f-test}

For non-normal data, the distribution of the sample variance may deviate
substantially from a Ï‡2 distribution. However, if the sample size is
large, Slutsky's theorem implies that the distribution of the sample
variance has little effect on the distribution of the test statistic.

    \section{Hypothesis Testing}\label{hypothesis-testing}

For the unequal variance t test, the null hypothesis is that the two
population means are the same but the two population variances may
differ. If the P value is large, you don't reject that null hypothesis,
so conclude that the evidence does not persuade you that the two
population means are different, even though you assume the two
populations have (or may have) different standard deviations. What a
strange set of assumptions. What would it mean for two populations to
have the same mean but different standard deviations? Why would you want
to test for that? Swailowsky points out that this situation simply
doesn't often come up in science (1).

I think the unequal variance t test is more useful when you think about
it as a way to create a confidence interval. Your prime goal is not to
ask whether two populations differ, but to quantify how far apart the
two means are. The unequal variance t test reports a confidence interval
for the difference between two means that is usable even if the standard
deviations differ.

\textbf{Single sample vs Two samples}

\textbf{Two-tailed vs one-tailed}

For example, we may wish to compare the mean of a sample to a given
value x using a t-test. Our null hypothesis is that the mean is equal to
x. A two-tailed test will test both if the mean is significantly greater
than x and if the mean significantly less than x. The mean is considered
significantly different from x if the test statistic is in the top 2.5\%
or bottom 2.5\% of its probability distribution, resulting in a p-value
less than 0.05

Our null hypothesis is that the mean is equal to x. A one-tailed test
will test either if the mean is significantly greater than x or if the
mean is significantly less than x, but not both. Then, depending on the
chosen tail, the mean is significantly greater than or less than x if
the test statistic is in the top 5\% of its probability distribution or
bottom 5\% of its probability distribution, resulting in a p-value less
than 0.05. The one-tailed test provides more power to detect an effect
in one direction by not testing the effect in the other direction

\textbf{When is one-tailed appropriate?}

Imagine you have developed a new drug that you believe is an improvement
over an existing drug. You wish to maximize your ability to detect the
improvement, so you opt for a one-tailed test. In doing so, you fail to
test for the possibility that the new drug is less effective than the
existing drug.

In testing this drug, you are only interested in testing if it less
effective than the existing drug. You do not care if it is significantly
more effective. You only wish to show that it is not less effective. In
this scenario, a one-tailed test would be appropriate.

https://stackoverflow.com/questions/15984221/how-to-perform-two-sample-one-tailed-t-test-with-numpy-scipy

Unqual variance t-test

https://www.graphpad.com/support/faqid/1568/

https://towardsdatascience.com/kolmogorov-smirnov-test-84c92fb4158d

There is an issue with Student's T-Test, samples must be normal (shaped
in a normal distribution). That is an issue for us because we do work a
lot with Poisson distributions.

\section{Really good t-test article}\label{really-good-t-test-article}

https://www.investopedia.com/terms/t/t-test.asp

\section{Paired vs unpaired t-test}\label{paired-vs-unpaired-t-test}

https://www.quora.com/What-is-the-difference-between-a-paired-and-unpaired-t-test

\section{Different Sample Sizes}\label{different-sample-sizes}

https://stats.stackexchange.com/questions/31326/how-should-one-interpret-the-comparison-of-means-from-different-sample-sizes

think of this by analogy. If you want to know the area of a rectangle,
and the perimeter is fixed, then the area will be maximized if the
length and width are equal (i.e., if the rectangle is a square). On the
other hand, as the length and width diverge (as the rectangle becomes
elongated), the area shrinks.

\section{Levene's test}\label{levenes-test}

It tests the null hypothesis that the population variances are equal
(called homogeneity of variance or homoscedasticity)

\section{K.S. test}\label{k.s.-test}

My instructor in this topic joked: Kolmogorov-Smirnov is a test for
sample size.

It has no power in small samples, and intense power, with no particular
sensible acceptance of deviations from normal, in large samples.

The Kolmogorov-Smirnov (KS) test is used in over 500 refereed papers
each year in the astronomical literature. It is a nonparametric
hypothesis test that measures the probability that a chosen univariate
dataset is drawn from the same parent population as a second dataset
(the two-sample KS test) or a continuous model (the one-sample KS test).

It measures the greatest distance between the two CDF's. The underlying
population distribution is assumed to be continuous.

https://asaip.psu.edu/Articles/beware-the-kolmogorov-smirnov-test

\emph{Question:} How good is KS test if sample size is small?

even when valid to apply, it is often not very sensitive in establishing
distances between two distributions, and a similar EDF-based test gives
a better performance.

https://stats.stackexchange.com/questions/57885/how-to-interpret-p-value-of-kolmogorov-smirnov-test-python

he k-s test returns a D statistic and a p-value corresponding to the D
statistic. The D statistic is the absolute max distance (supremum)
between the CDFs of the two samples. The closer this number is to 0 the
more likely it is that the two samples were drawn from the same
distribution. The p-value returned by the k-s test has the same
interpretation as other p-values. You reject the null hypothesis that
the two samples were drawn from the same distribution if the p-value is
less than your significance level.

\textbf{Best when comparing two non-parametric samples}

But less powerful when comparing to reference distribution, like normal
distribution.

Shapiro-Wilk is known to be bad with samples with many identical values.

\section{Non-normal distribution}\label{non-normal-distribution}

Mann-Whitney U test, Bootstrapping,
\href{https://amstat.tandfonline.com/doi/full/10.1080/10691898.2005.11910638\#.XQvVFtNKhQI}{lognormal},
bayisean

CI of medians

Normality assumption of a t-test

Consider a large population from which you could take many different
samples of a particular size. (In a particular study, you generally
collect just one of these samples.)

By the central limit theorem, means of samples from a population with
finite variance approach a normal distribution regardless of the
distribution of the population. Rules of thumb say that the sample means
are basically normally distributed as long as the sample size is at
least 20 or 30. For a t-test to be valid on a sample of smaller size,
the population distribution would have to be approximately normal.

https://stats.stackexchange.com/questions/9573/t-test-for-non-normal-when-n50

T-test is fine on non-normal data, as long as the deviation from
normality isn't large. Visualize your distributions to test this.

The advice must be modified somewhat when the distributions are both
strongly skewed and very discrete, such as Likert scale items where most
of the observations are in one of the end categories. Then the
Wilcoxon-Mann-Whitney isn't necessarily a better choice than the t-test.

Nonparametric t-Tests The Mann--Whitney U test is the true nonparametric
counterpart of the t-test and gives the most accurate estimates of
significance, especially when sample sizes are small and/or when the
data do not approximate a normal distribution.

However, there is something familiar and comforting about using t-tests!
When one has a large sample size (N â‰« 30) but the data are skewed, it is
worth examining log- or square root-transformed values of the data to
see if they become more quasinormal (see Chapter 7). If the data pass a
test for normality (included in most statistical software), it is then
OK to perform a t-test using the transformed datapoints.

When the normality assumption does not hold, a non-parametric
alternative to the t-test can often have better statistical power.

In the presence of an outlier, the t-test is not robust. For example,
for two independent samples when the data distributions are asymmetric
(that is, the distributions are skewed) or the distributions have large
tails, then the Wilcoxon rank-sum test (also known as the Mann--Whitney
U test) can have three to four times higher power than the
t-test.{[}14{]}{[}15{]}{[}16{]} The nonparametric counterpart to the
paired samples t-test is the Wilcoxon signed-rank test for paired
samples. For a discussion on choosing between the t-test and
nonparametric alternatives, see Sawilowsky (2005

https://stats.stackexchange.com/questions/49465/mann-whitney-for-non-normal-distributions-with-n20?rq=1

In Moore, McCabe, Craig's Introduction to the Practice of Statistics
(6th ed., pg. 432): For sample sizes 15â‰¤ n â‰¤39, "t procedures can be
used except in the presence of outliers or strong skewness." For samples
sizes â‰¥40, "t procedures can be used even for clearly skewed
distributions."

The t tends to have reasonably good power relative to the MW for
light-tailed distributions ... and can have really bad power for
heavy-tailed ones. Skewness tends to be compounded with heavy tails - if
power is your main motivation for using the t-test, you should probably
avoid it in this case.

There's also the possibility of a permutation test rather than either of
the choices you mention - it would allow you to test a difference in
means and have it be valid when the assumptions of the t-test are not
satisfied.

\section{Different distribution
distances}\label{different-distribution-distances}

https://statweb.stanford.edu/\textasciitilde{}souravc/Lecture2.pdf

\section{Normality testing in extremely large sample
sizes}\label{normality-testing-in-extremely-large-sample-sizes}

https://stats.stackexchange.com/questions/2492/is-normality-testing-essentially-useless

The question normality tests answer: Is there convincing evidence of any
deviation from the Gaussian ideal? With moderately large real data sets,
the answer is almost always yes.

The question scientists often expect the normality test to answer: Do
the data deviate enough from the Gaussian ideal to "forbid" use of a
test that assumes a Gaussian distribution? Scientists often want the
normality test to be the referee that decides when to abandon
conventional (ANOVA, etc.) tests and instead analyze transformed data or
use a rank-based nonparametric test or a resampling or bootstrap
approach. For this purpose, normality tests are not very useful.

\textbf{Use skewness or kurtosis as a to test normality instead}

t can be verified using simulations that this is true for small ð‘› as
well. Thus Student's t-test is sensitive to skewness but relatively
robust against heavy tails, and it is reasonable to use a test for
normality that is directed towards skew alternatives before applying the
t-test.

As a rule of thumb (not a law of nature), inference about means is
sensitive to skewness and inference about variances is sensitive to
kurtosis. - \textbf{you can use bootstrap in conjuction with normality
test to get threshold value of good kurtosis and skewness}

On large samples, things like the T-test and ANOVA are pretty robust to
non-normality.

The t-test assumes that the means of the different samples are normally
distributed; it does not assume that the population is normally
distributed.

By the central limit theorem, means of samples from a population with
finite variance approach a normal distribution regardless of the
distribution of the population.

A confidence interval's width is due entirely to sampling error. As the
sample size approaches the entire population, the width of the
confidence interval approaches zero.

    \subsubsection{Examples}\label{examples}

Example Suppose a student measuring the boiling temperature of a certain
liquid observes the readings (in degrees Celsius) 102.5, 101.7, 103.1,
100.9, 100.5, and 102.2 on 6 different samples of the liquid. He
calculates the sample mean to be 101.82. If he knows that the standard
deviation for this procedure is 1.2 degrees, what is the confidence
interval for the population mean at a 95\% confidence level?

In other words, the student wishes to estimate the true mean boiling
temperature of the liquid using the results of his measurements. If the
measurements follow a normal distribution, then the sample mean will
have the distribution N(,). Since the sample size is 6, the standard
deviation of the sample mean is equal to 1.2/sqrt(6) = 0.49.

    \section{Outliers}\label{outliers}

T-test is sensitive to outliers. Outliers are important, because they
affect the shape of normal distribution. Add one outlier, and run
saphiro-wilk normality test, and the result will be significantly
different. Using IQR outlier detection might not be good too, because
the IQR themselves have outliers in them

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k+kn}{from} \PY{n+nn}{scipy} \PY{k}{import} \PY{n}{stats}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
        
        \PY{n}{a} \PY{o}{=} \PY{p}{[}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{6}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{4}\PY{p}{]}
        
        \PY{n}{stats}\PY{o}{.}\PY{n}{norm}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mf}{0.95}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{o}{/}\PY{n}{np}\PY{o}{.}\PY{n}{sqrt}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:} (2.39885356840566, 4.35114643159434)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}\PY{o}{,} \PY{n+nn}{scipy}\PY{n+nn}{.}\PY{n+nn}{stats} \PY{k}{as} \PY{n+nn}{st}
        
        \PY{n}{st}\PY{o}{.}\PY{n}{t}\PY{o}{.}\PY{n}{interval}\PY{p}{(}\PY{l+m+mf}{0.95}\PY{p}{,} \PY{n+nb}{len}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{loc}\PY{o}{=}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{,} \PY{n}{scale}\PY{o}{=}\PY{n}{st}\PY{o}{.}\PY{n}{sem}\PY{p}{(}\PY{n}{a}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} (2.11600213750892, 4.63399786249108)
\end{Verbatim}
            
    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor} }]:} \PY{n}{Many} \PY{n}{statistical} \PY{n}{techniques} \PY{n}{assume} \PY{n}{that} \PY{n}{sample} \PY{n}{data} \PY{o+ow}{is} \PY{n}{normally} \PY{n}{distributed} \PY{o+ow}{or} \PY{n}{Gaussian}\PY{o}{\PYZhy{}}\PY{n}{like} \PY{p}{(}\PY{n}{Ex}\PY{p}{:} \PY{n}{t}\PY{o}{\PYZhy{}}\PY{n}{distribution}\PY{p}{)}\PY{p}{,} \PY{o+ow}{and} \PY{n}{different} \PY{n}{techniques} \PY{n}{should} \PY{n}{be} \PY{n}{considered} \PY{k}{for} \PY{n}{non}\PY{o}{\PYZhy{}}\PY{n}{normal} \PY{n}{data} \PY{n+nb}{set}\PY{o}{.}
\end{Verbatim}


    \subsection{Similarity of
distributions}\label{similarity-of-distributions}

https://stats.stackexchange.com/questions/77888/similarity-between-two-sets-of-random-values

    \subsection{Smart Gas Lift}\label{smart-gas-lift}

gas lift - use external high pressure gas, well has gas in it, but not
enough. Inject in through the casing, tubing, and lift hydrocarbons up
with the gas. High pressure compression makes the lifespan of machine
short.

Inject too little gas - don't lift enough. Doesn't flow all the way
Inject too much gas - you are gonna lift it all, but you add extra
friction, and you waste gas that you can sell.

GOR affects how much gas you need to inject.

Based on experience, opt injection rate seems to always round about 500,
600, 700 mcfd.

Key features - self-optimization, maximizing runtime. We have 95\%
runtime, but others have 60-70\% runtime. - you can't manually determin
BHP, but the algo does it automatically with iterations.

\section{Mahalanobis distance}\label{mahalanobis-distance}

https://stats.stackexchange.com/questions/62092/bottom-to-top-explanation-of-the-mahalanobis-distance

    \emph{Distribution score} depends on the type of distribution (Ex:
normal, lognormal, chi-squared, weibull), and the equations for
\emph{standard error} depends on the type of statistic (Ex: mean,
proportion, std, variance). The sample data is assumed to be normally
distributed, allowing you to use z-score to lookup values related to any
confidence level (Ex: 99\%, 95\%, 90\%). Since you are trying to compute
confidence interval of a mean (\(\overline{x}\)), you use
\(SE_{\overline{x}} = s\,/\sqrt{N}\) to compute standard error for a
mean.


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
